{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi object tracking in complex urban scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed \n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# upload data \n",
    "hdf5data_109 = h5py.File('../../Data/data_109.h5', 'r')\n",
    "hdf5data_130 = h5py.File('../../Data/data_130.h5', 'r')\n",
    "hdf5data_142 = h5py.File('../../Data/data_142.h5', 'r')\n",
    "hdf5data_143 = h5py.File('../../Data/data_143.h5', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer data into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_rows_detections(detections, returndf):\n",
    "    \n",
    "    coord_detections = [np.array(vals[0].tolist()) for vals in detections]\n",
    "    coord_detections = np.vstack(coord_detections)\n",
    "        \n",
    "    length_box = [vals[1] for vals in detections]\n",
    "    width_box = [vals[2] for vals in detections]\n",
    "    height_box = [vals[3] for vals in detections]\n",
    "    angle_box = [vals[4] for vals in detections]\n",
    "    \n",
    "    returndf[\"X_box\"] = coord_detections[:,0]\n",
    "    returndf[\"Y_box\"] = coord_detections[:,1]\n",
    "    returndf[\"Z_box\"] = coord_detections[:,2]\n",
    "    returndf[\"length_box\"], returndf[\"width_box\"], returndf[\"height_box\"] = length_box, width_box, height_box\n",
    "    returndf[\"angle_box\"] = angle_box\n",
    "    \n",
    "    return returndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_detections(h5data,camera = None):\n",
    "    \n",
    "    timestamps = h5data['Timestamp']\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for c, t in enumerate(timestamps):\n",
    "        \n",
    "        append_df = pd.DataFrame()\n",
    "        \n",
    "        d = h5data['Sequence'][str(c)]\n",
    "        detection = np.asarray(d['Detections'])\n",
    "        \n",
    "        if detection.size:\n",
    "            append_df = fill_rows_detections(detection, append_df)\n",
    "            append_df['timestamp'] = t\n",
    "            append_df['frame'] = c\n",
    "        \n",
    "            if camera is not None:\n",
    "                append_df['camera'] = camera\n",
    "        \n",
    "            df = df.append(append_df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_109 = df_detections(hdf5data_109, 109)\n",
    "df_109.reset_index(inplace=True, drop=True)\n",
    "df_130 = df_detections(hdf5data_130, 130)\n",
    "df_130.reset_index(inplace=True, drop=True)\n",
    "df_142 = df_detections(hdf5data_142, 142)\n",
    "df_142.reset_index(inplace=True, drop=True)\n",
    "df_143 = df_detections(hdf5data_143, 143)\n",
    "df_143.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_box</th>\n",
       "      <th>Y_box</th>\n",
       "      <th>Z_box</th>\n",
       "      <th>length_box</th>\n",
       "      <th>width_box</th>\n",
       "      <th>height_box</th>\n",
       "      <th>angle_box</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>frame</th>\n",
       "      <th>camera</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.148409</td>\n",
       "      <td>15.363879</td>\n",
       "      <td>-0.941920</td>\n",
       "      <td>1.177285</td>\n",
       "      <td>0.561967</td>\n",
       "      <td>1.334849</td>\n",
       "      <td>0.631927</td>\n",
       "      <td>1.574333e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.560173</td>\n",
       "      <td>18.983654</td>\n",
       "      <td>-1.377405</td>\n",
       "      <td>3.325998</td>\n",
       "      <td>0.953963</td>\n",
       "      <td>1.498572</td>\n",
       "      <td>-0.120755</td>\n",
       "      <td>1.574333e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.373729</td>\n",
       "      <td>28.175323</td>\n",
       "      <td>-1.134802</td>\n",
       "      <td>5.493111</td>\n",
       "      <td>1.930805</td>\n",
       "      <td>2.056836</td>\n",
       "      <td>1.514860</td>\n",
       "      <td>1.574333e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.546980</td>\n",
       "      <td>26.314280</td>\n",
       "      <td>-0.862299</td>\n",
       "      <td>1.506848</td>\n",
       "      <td>0.592773</td>\n",
       "      <td>1.134711</td>\n",
       "      <td>0.424306</td>\n",
       "      <td>1.574333e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.382445</td>\n",
       "      <td>-4.612707</td>\n",
       "      <td>-1.015361</td>\n",
       "      <td>4.811726</td>\n",
       "      <td>2.805154</td>\n",
       "      <td>1.550568</td>\n",
       "      <td>1.004918</td>\n",
       "      <td>1.574333e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0.047641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11740</th>\n",
       "      <td>-5.128264</td>\n",
       "      <td>26.316446</td>\n",
       "      <td>-1.150593</td>\n",
       "      <td>2.670343</td>\n",
       "      <td>1.157835</td>\n",
       "      <td>1.589266</td>\n",
       "      <td>-0.424405</td>\n",
       "      <td>1.574333e+09</td>\n",
       "      <td>749</td>\n",
       "      <td>109</td>\n",
       "      <td>59.920729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11741</th>\n",
       "      <td>-1.906789</td>\n",
       "      <td>-5.313489</td>\n",
       "      <td>-2.293509</td>\n",
       "      <td>3.833054</td>\n",
       "      <td>0.585950</td>\n",
       "      <td>0.395508</td>\n",
       "      <td>-0.462055</td>\n",
       "      <td>1.574333e+09</td>\n",
       "      <td>749</td>\n",
       "      <td>142</td>\n",
       "      <td>59.927601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11742</th>\n",
       "      <td>-1.142268</td>\n",
       "      <td>-3.922715</td>\n",
       "      <td>-2.524621</td>\n",
       "      <td>12.753714</td>\n",
       "      <td>0.377229</td>\n",
       "      <td>1.433762</td>\n",
       "      <td>-0.278929</td>\n",
       "      <td>1.574333e+09</td>\n",
       "      <td>749</td>\n",
       "      <td>142</td>\n",
       "      <td>59.927601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11743</th>\n",
       "      <td>14.617583</td>\n",
       "      <td>-29.436074</td>\n",
       "      <td>-1.085488</td>\n",
       "      <td>5.046473</td>\n",
       "      <td>2.802799</td>\n",
       "      <td>1.898150</td>\n",
       "      <td>-1.309933</td>\n",
       "      <td>1.574333e+09</td>\n",
       "      <td>749</td>\n",
       "      <td>143</td>\n",
       "      <td>59.967542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11744</th>\n",
       "      <td>10.872921</td>\n",
       "      <td>-6.188014</td>\n",
       "      <td>-0.909208</td>\n",
       "      <td>7.566915</td>\n",
       "      <td>3.033707</td>\n",
       "      <td>1.567966</td>\n",
       "      <td>0.852289</td>\n",
       "      <td>1.574333e+09</td>\n",
       "      <td>749</td>\n",
       "      <td>143</td>\n",
       "      <td>59.967542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11745 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X_box      Y_box     Z_box  length_box  width_box  height_box  \\\n",
       "0     -11.148409  15.363879 -0.941920    1.177285   0.561967    1.334849   \n",
       "1      -9.560173  18.983654 -1.377405    3.325998   0.953963    1.498572   \n",
       "2       3.373729  28.175323 -1.134802    5.493111   1.930805    2.056836   \n",
       "3       6.546980  26.314280 -0.862299    1.506848   0.592773    1.134711   \n",
       "4      14.382445  -4.612707 -1.015361    4.811726   2.805154    1.550568   \n",
       "...          ...        ...       ...         ...        ...         ...   \n",
       "11740  -5.128264  26.316446 -1.150593    2.670343   1.157835    1.589266   \n",
       "11741  -1.906789  -5.313489 -2.293509    3.833054   0.585950    0.395508   \n",
       "11742  -1.142268  -3.922715 -2.524621   12.753714   0.377229    1.433762   \n",
       "11743  14.617583 -29.436074 -1.085488    5.046473   2.802799    1.898150   \n",
       "11744  10.872921  -6.188014 -0.909208    7.566915   3.033707    1.567966   \n",
       "\n",
       "       angle_box     timestamp  frame  camera  elapsed_time  \n",
       "0       0.631927  1.574333e+09      0     109      0.000000  \n",
       "1      -0.120755  1.574333e+09      0     109      0.000000  \n",
       "2       1.514860  1.574333e+09      0     109      0.000000  \n",
       "3       0.424306  1.574333e+09      0     109      0.000000  \n",
       "4       1.004918  1.574333e+09      0     130      0.047641  \n",
       "...          ...           ...    ...     ...           ...  \n",
       "11740  -0.424405  1.574333e+09    749     109     59.920729  \n",
       "11741  -0.462055  1.574333e+09    749     142     59.927601  \n",
       "11742  -0.278929  1.574333e+09    749     142     59.927601  \n",
       "11743  -1.309933  1.574333e+09    749     143     59.967542  \n",
       "11744   0.852289  1.574333e+09    749     143     59.967542  \n",
       "\n",
       "[11745 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concatenate_dfs(dfs, sort_cols):\n",
    "    \n",
    "    df_to_concat = dfs\n",
    "    df_complete = pd.concat(df_to_concat)\n",
    "    df_complete.sort_values(by = sort_cols, inplace = True)\n",
    "    df_complete.reset_index(inplace=True, drop=True)\n",
    "    df_complete['elapsed_time'] = df_complete['timestamp']-df_complete['timestamp'].min()\n",
    "    \n",
    "    return df_complete\n",
    "\n",
    "df_complete = concatenate_dfs([df_109,df_130,df_142,df_143] , ['frame', 'camera'])\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add reliability of measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define coordinate transformation useful to find credibility levels\n",
    "def convert_to_image_space ( coordinates , world2cam , cam2im ):\n",
    "    \"\"\" Input single set of coordinatetes \"\"\"\n",
    "    coord_4 = np.ones (4)\n",
    "    coord_4[0:3] = coordinates\n",
    "    cams_coord = ( np.matmul( world2cam , coord_4.T )).T\n",
    "    cams_coord_4 = np.ones(4)\n",
    "    \n",
    "    cams_coord_4 [0:3] = cams_coord [0:3]\n",
    "    ims_coord = ( np . matmul ( cam2im , cams_coord_4 .T )). T\n",
    "    # Divide by z coordinate for some reason\n",
    "    ims_coord [0] = ims_coord [0]/ ims_coord [2]\n",
    "    ims_coord [1] = ims_coord [1]/ ims_coord [2]\n",
    "    ims_coord = ims_coord [0:2]\n",
    "    \n",
    "    return ( ims_coord )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credibility_level(df):\n",
    "    df['credibility_level'] = np.zeros(shape = len(df.index))\n",
    "    for ind,row in df.iterrows():\n",
    "        coordinates = row[['X_box','Y_box','Z_box']]\n",
    "        \n",
    "        if row['camera'] == 109: \n",
    "            df.at[ind,'credibility_level'] = level_affidability_109(coordinates);\n",
    "            \n",
    "                    \n",
    "        elif row['camera'] == 130:\n",
    "            df.at[ind,'credibility_level'] = level_affidability_130(coordinates);\n",
    "            \n",
    "            \n",
    "        elif row['camera'] == 142:\n",
    "            df.at[ind,'credibility_level'] = level_affidability_142(coordinates);\n",
    "         \n",
    "        \n",
    "        if row['camera'] == 143:\n",
    "            df.at[ind,'credibility_level'] = level_affidability_143(coordinates);\n",
    "        \n",
    "\n",
    "                \n",
    "def level_affidability_109(coordinates):\n",
    "    world2cam = hdf5data_109['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_109['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    sloap1 = (-250 + 121.374145)/(600-296.40511363)\n",
    "    sloap2 = 8/65\n",
    "    if - img_coord[1] <= sloap1*(img_coord[0] - 600) - 250:\n",
    "        return 1\n",
    "    elif - img_coord[1] <= sloap2*(img_coord[0]) - 180:\n",
    "        return 0.75\n",
    "    else:\n",
    "        return 0.25\n",
    "\n",
    "    \n",
    "def level_affidability_130(coordinates):\n",
    "    world2cam = hdf5data_130['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_130['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    if (img_coord[0] <= 630) & (img_coord[1] >= 100):\n",
    "        return 1\n",
    "    elif (img_coord[0] >= 420):\n",
    "        return 0.25\n",
    "    else: \n",
    "        return 0.5\n",
    "    \n",
    "\n",
    "    \n",
    "def level_affidability_142(coordinates):\n",
    "    world2cam = hdf5data_142['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_142['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    if (img_coord[0] >= 535) & (img_coord[0] <= 575) & (img_coord[1] <= 160) & (img_coord[1] >= 50):\n",
    "        return 0.25\n",
    "    if (img_coord[0] <= 570) & (img_coord[0] >= 380) & (img_coord[1] <= 70):\n",
    "        return 0.25\n",
    "    elif img_coord[1] > 70:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0.75\n",
    "\n",
    "    \n",
    "def level_affidability_143(coordinates):\n",
    "    world2cam = hdf5data_143['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_143['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    if (img_coord[0] >= 420) & (img_coord[1] <= 120):\n",
    "        return 0.25\n",
    "    if (img_coord[0] < 410) & (img_coord[1] <= 120):\n",
    "        return 0.5\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credibility_level(df_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_frame_detections ( camera, frame_idx, figsize = None , s = 100):\n",
    "    \"\"\" Input camera file, frame index and size of dot in the picture (default is 100) \"\"\"\n",
    "    \n",
    "    frame = camera['Sequence'][str(frame_idx)]\n",
    "    detected_points = np.asarray(frame['Detections'])\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for point in detected_points:\n",
    "    \n",
    "        world_pos = np.array(point[0].tolist())\n",
    "        fin_pos = convert_to_image_space(world_pos, camera['TMatrixWorldToCam'], camera['ProjectionMatrix'])\n",
    "        x_list.append(fin_pos[0])\n",
    "        y_list.append(fin_pos[1])\n",
    "    \n",
    "    \n",
    "\n",
    "    # Show image\n",
    "    a = np.asarray(frame['Image'])\n",
    "    \n",
    "    if figsize is not None: \n",
    "        plt.figure(figsize = figsize)\n",
    "        \n",
    "    plt.imshow(a, cmap = 'gist_gray', zorder = 1)\n",
    "    plt.scatter(x_list, y_list, s = s, color = 'hotpink', zorder = 3)\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def visualize_frame_boxes ( camera, frame_idx, figsize = None, s = 100):\n",
    "    \"\"\" Input camera file, frame index and size of dot in the picture (default is 100) \"\"\"\n",
    "    \n",
    "    frame = camera['Sequence'][str(frame_idx)]\n",
    "    detected_points = np.asarray(frame['Detections'])\n",
    "    \n",
    "    if figsize is not None: \n",
    "        plt.figure(figsize = figsize)\n",
    "        \n",
    "    \n",
    "    for point in detected_points:\n",
    "        # first face \n",
    "        unrotated_vertex1 = np.array([+ point['Length']/2, + point['Width']/2, + point['Height']/2])\n",
    "        unrotated_vertex2 = np.array([+ point['Length']/2, + point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex3 = np.array([+ point['Length']/2, - point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex4 = np.array([+ point['Length']/2, - point['Width']/2, + point['Height']/2])\n",
    "        # second face \n",
    "        unrotated_vertex5 = np.array([- point['Length']/2, + point['Width']/2, + point['Height']/2])\n",
    "        unrotated_vertex6 = np.array([- point['Length']/2, + point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex7 = np.array([- point['Length']/2, - point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex8 = np.array([- point['Length']/2, - point['Width']/2, + point['Height']/2])\n",
    "        \n",
    "        \n",
    "        unrotated_vertex_list = [unrotated_vertex1, unrotated_vertex2, unrotated_vertex3, \n",
    "                                 unrotated_vertex4, unrotated_vertex5, unrotated_vertex6, \n",
    "                                 unrotated_vertex7, unrotated_vertex8]\n",
    "        \n",
    "        rotation_matrix = np.array([[np.cos(point['Angle']), -np.sin(point['Angle']), 0], \n",
    "                            [np.sin(point['Angle']), np.cos(point['Angle']), 0], \n",
    "                            [0,0,1]])\n",
    "        \n",
    "        rotated_vertex_list = np.array([rotation_matrix.dot(v) for v in unrotated_vertex_list])\n",
    "        rotated_vertex_list = rotated_vertex_list + np.array([point['Pos']['X'], point['Pos']['Y'], point['Pos']['Z']])\n",
    "        \n",
    "        vertex_im_list = [convert_to_image_space(v, camera['TMatrixWorldToCam'], camera['ProjectionMatrix']) for v in rotated_vertex_list]\n",
    "        \n",
    "        \n",
    "        combinations = [(i,i+1) for i in range(3)] + [(3,0)] + [(i,i+1) for i in range(4,7)] + [\n",
    "            (7,4)] + [(i,i+4) for i in range(4)]\n",
    "        \n",
    "        for (i,j) in combinations: \n",
    "            vertex_x_list = [vertex_im_list[i][0],vertex_im_list[j][0]]\n",
    "            vertex_y_list = [vertex_im_list[i][1],vertex_im_list[j][1]]\n",
    "            plt.plot(vertex_x_list, vertex_y_list, color = 'b', zorder = 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    visualize_frame_detections ( camera, frame_idx, s = s )\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def visualize_alldetections(df, frame_idx = None):\n",
    "    ''' Visualize all detections from above'''\n",
    "    if frame_idx is not None:\n",
    "        x = df['X_box'][df['frame'] == frame_idx]\n",
    "        y = df['Y_box'][df['frame'] == frame_idx]\n",
    "        display(df[df['frame'] == frame_idx])\n",
    "    \n",
    "    else:\n",
    "        x = df['X_box']\n",
    "        y = df['Y_box']\n",
    "        \n",
    "    plt.scatter(x,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_frame_detections(hdf5data_143,313, figsize = (12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_frame_boxes(hdf5data_109, 260, figsize = (12,12), s = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_alldetections(df_complete, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define some useful constants\n",
    "\n",
    "dt = 0.08\n",
    "new_time_threshold = 7\n",
    "active_time_threshold = 5\n",
    "speed_acc_window = 5\n",
    "H = np.array([[1.,0.,0., 0., 0., 0., 0., 0., 0.],[0.,0., 0.,1., 0., 0., 0., 0., 0.],[0.,0., 0., 0., 0., 0.,1., 0., 0.]])\n",
    "max_dist_threshold = 5\n",
    "\n",
    "\n",
    "def linear_transition_matrix(dt):\n",
    "    \"\"\"Returns matrix F of the Constant Acceleration model\"\"\"\n",
    "    return np.array([[1., dt, 0.5*dt**2, 0., 0., 0., 0., 0., 0.], [0, 1, dt, 0., 0., 0., 0., 0., 0. ], [0.,0.,1., 0., 0., 0., 0., 0., 0.],\n",
    "               [0.,0.,0.,1.,dt,0.5*dt**2,0.,0.,0.],[0.,0.,0.,0.,1.,dt,0.,0.,0.],[0.,0.,0.,0.,0.,1.,0.,0.,0.],\n",
    "               [0.,0.,0.,0.,0.,0.,1.,dt,0.5*dt**2],[0.,0.,0.,0.,0.,0.,0.,1.,dt], [0.,0.,0.,0.,0.,0.,0.,0.,1.]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class representing a single detection\n",
    "\n",
    "class Object:\n",
    "    def __init__(self, x, y, z, l, w, h, angle, camera):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.length = l\n",
    "        self.width = w\n",
    "        self.height = h\n",
    "        self.angle = angle\n",
    "        self.camera = camera\n",
    "        \n",
    "    def to_df(self):\n",
    "        \n",
    "        df = pd.DataFrame([[self.x, self.y, self.z, self.length, self.width, self.height, self.angle, self.camera]], \n",
    "                         columns = ['X_box', 'Y_box', 'Z_box', 'length_box', 'width_box', 'height_box', 'angle_box', 'camera'])\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"x: %f, y:%f, z:%f, length:%f, width:%f, height:%f, angle:%f, camera:%d \\n\" %(self.x, self.y, self.z, self.length, self.width, self.height, self.angle, self.camera)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"x: %f, y:%f, z:%f \\n\" %(self.x, self.y, self.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class representing the Tracks\n",
    "\n",
    "class Track:\n",
    "    \n",
    "    def __init__(self, ID, OBJ, FRAME, threshold = new_time_threshold):\n",
    "        self.ID = ID\n",
    "        self.status = 'New' \n",
    "        self.objects = [OBJ]\n",
    "        self.x, self.y, self.z = OBJ.x, OBJ.y, OBJ.z\n",
    "        self.frames = [FRAME]\n",
    "        self.velocity = [0.5, 0.5, 0.5]\n",
    "        self.acceleration = [0.2, 0.2, 0.2]\n",
    "        self.type = None\n",
    "        self.threshold = threshold\n",
    "        self.filter = None\n",
    "        self.new_time = 1\n",
    "        self.pending_time = 0\n",
    "        self.active_time = 0\n",
    "        self.all_positions = [[OBJ.x, OBJ.y, OBJ.z]]\n",
    "        self.all_velocities = [[], [], []]\n",
    "        self.all_accelerations = [[], [], []]\n",
    "        self.pending_status = []\n",
    "        self.all_kfs = []\n",
    "        \n",
    "        \n",
    "        self.set_Kalman_Filter(x0 = OBJ)\n",
    "    \n",
    "    def update(self, OBJ, FRAME):\n",
    "        \"\"\"Performs different update routines based on the presence of an associated object or not, and the current status of the track\"\"\"\n",
    "        # predict next state through KF\n",
    "        self.filter.predict()\n",
    "        \n",
    "        # update with object\n",
    "        if OBJ is not None:\n",
    "            self.objects.append(OBJ)\n",
    "            self.frames.append(FRAME)\n",
    "            # update of a new trajectory - velocity and acceleration are estimated through sample averages of observed positions for improving the start conditions\n",
    "            if self.status == 'New':\n",
    "                self.x, self.y, self.z = OBJ.x, OBJ.y, OBJ.z\n",
    "                last_xs = np.array([obj.x for obj in self.objects])\n",
    "                last_ys = np.array([obj.y for obj in self.objects])\n",
    "                last_zs = np.array([obj.z for obj in self.objects])\n",
    "                if len(last_xs)>1:\n",
    "                    self.velocity[0] = np.mean((last_xs[1:]-last_xs[:-1])/dt)\n",
    "                    self.velocity[1] = np.mean((last_ys[1:]-last_ys[:-1])/dt)\n",
    "                    self.velocity[2] = np.mean((last_zs[1:]-last_zs[:-1])/dt)\n",
    "                    \n",
    "                if len(last_xs)>2:\n",
    "                    fin2dx = np.array(last_xs[2:] - 2* last_xs[1:-1] + last_xs[:-2])/(dt**2)\n",
    "                    fin2dx[np.abs(fin2dx)>9.8] = 9.8 * np.sign(fin2dx[np.abs(fin2dx)>9.8])\n",
    "                    fin2dy = np.array(last_ys[2:] - 2* last_ys[1:-1] + last_ys[:-2])/(dt**2)\n",
    "                    fin2dy[np.abs(fin2dy)>9.8] = 9.8 * np.sign(fin2dy[np.abs(fin2dy)>9.8])\n",
    "                    fin2dz = np.array(last_zs[2:] - 2* last_zs[1:-1] + last_zs[:-2])/(dt**2)\n",
    "                    fin2dz[np.abs(fin2dz)>9.8] = 9.8 * np.sign(fin2dz[np.abs(fin2dz)>9.8])\n",
    "                    self.acceleration[0] = np.mean(fin2dx)\n",
    "                    self.acceleration[1] = np.mean(fin2dy)\n",
    "                    self.acceleration[2] = np.mean(fin2dz)\n",
    "                \n",
    "                self.filter.x = np.array([self.x,self.velocity[0], self.acceleration[0],\n",
    "                                          self.y,self.velocity[1], self.acceleration[1],\n",
    "                                          self.z,self.velocity[2], self.acceleration[2]])\n",
    "                self.new_time += 1\n",
    "                if self.new_time > self.threshold:\n",
    "                    self.status = 'Active'\n",
    "                    self.active_time = 1\n",
    "            else:\n",
    "                \n",
    "                # Kalman Filter is updated with observed values\n",
    "                self.update_Kalman_Filter(np.array([OBJ.x, OBJ.y, OBJ.z]))\n",
    "\n",
    "                # for some active time keep using the sample average estimated velocity and acceleration to ensure KF has enough time to converge\n",
    "                if self.active_time < active_time_threshold: \n",
    "                    self.x, self.y, self.z = OBJ.x, OBJ.y, OBJ.z\n",
    "                    last_xs = np.array([obj.x for obj in self.objects[-speed_acc_window:]])\n",
    "                    last_ys = np.array([obj.y for obj in self.objects[-speed_acc_window:]])\n",
    "                    last_zs = np.array([obj.z for obj in self.objects[-speed_acc_window:]])\n",
    "                    \n",
    "                    self.velocity[0] = np.mean((last_xs[1:]-last_xs[:-1])/dt)\n",
    "                    self.velocity[1] = np.mean((last_ys[1:]-last_ys[:-1])/dt)\n",
    "                    self.velocity[2] = np.mean((last_zs[1:]-last_zs[:-1])/dt)\n",
    "                    \n",
    "                    fin2dx = np.array(last_xs[2:] - 2* last_xs[1:-1] + last_xs[:-2])/(dt**2)\n",
    "                    fin2dx[np.abs(fin2dx)>9.8] = 9.8 * np.sign(fin2dx[np.abs(fin2dx)>9.8])\n",
    "                    fin2dy = np.array(last_ys[2:] - 2* last_ys[1:-1] + last_ys[:-2])/(dt**2)\n",
    "                    fin2dy[np.abs(fin2dy)>9.8] = 9.8 * np.sign(fin2dy[np.abs(fin2dy)>9.8])\n",
    "                    fin2dz = np.array(last_zs[2:] - 2* last_zs[1:-1] + last_zs[:-2])/(dt**2)\n",
    "                    fin2dz[np.abs(fin2dz)>9.8] = 9.8 * np.sign(fin2dz[np.abs(fin2dz)>9.8])\n",
    "                    self.acceleration[0] = np.mean(fin2dx)\n",
    "                    self.acceleration[1] = np.mean(fin2dy)\n",
    "                    self.acceleration[2] = np.mean(fin2dz)\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    self.x = self.filter.x[0]\n",
    "                    self.y = self.filter.x[3]\n",
    "                    self.z = self.filter.x[6]\n",
    "                    self.velocity = [self.filter.x[1], self.filter.x[4], self.filter.x[7]]\n",
    "                    self.acceleration = [self.filter.x[2], self.filter.x[5], self.filter.x[8]]\n",
    "                \n",
    "                \n",
    "                self.status = 'Active'\n",
    "                self.active_time += 1\n",
    "            self.all_positions.append([self.x,self.y,self.z])\n",
    "            self.all_velocities[0].append(self.velocity[0])\n",
    "            self.all_velocities[1].append(self.velocity[1])\n",
    "            self.all_velocities[2].append(self.velocity[2])\n",
    "            self.all_accelerations[0].append(self.acceleration[0]) \n",
    "            self.all_accelerations[1].append(self.acceleration[1])\n",
    "            self.all_accelerations[2].append(self.acceleration[2])\n",
    "            self.pending_status.append(0)\n",
    "        \n",
    "        # if no object is available, treat cases by either eliminating the trajectory or setting it as 'Pending'\n",
    "        if OBJ is None and self.status == 'New':\n",
    "            if self.new_time <= 3: \n",
    "                self.status = 'Removed'\n",
    "            else: \n",
    "                self.status = 'Pending'\n",
    "                self.pending_time = 0\n",
    "                \n",
    "        \n",
    "        if OBJ is None and self.status == 'Active':\n",
    "            self.status = 'Pending'\n",
    "            self.pending_time = 0\n",
    "        \n",
    "        if OBJ is None and self.status == 'Pending':                \n",
    "            self.pending_time += 1\n",
    "            if self.pending_time == 5:\n",
    "                self.status = 'Inactive'\n",
    "                self.all_positions = self.all_positions[:-5]\n",
    "            else: \n",
    "                self.x = self.filter.x[0]\n",
    "                self.y = self.filter.x[3]\n",
    "                self.z = self.filter.x[6]\n",
    "                self.velocity = [self.filter.x[1], self.filter.x[4], self.filter.x[7]]\n",
    "                self.acceleration = [self.filter.x[2], self.filter.x[5], self.filter.x[8]]\n",
    "                self.all_positions.append([self.x,self.y,self.z])\n",
    "                self.all_velocities[0].append(self.velocity[0])\n",
    "                self.all_velocities[1].append(self.velocity[1])\n",
    "                self.all_velocities[2].append(self.velocity[2])\n",
    "                self.all_accelerations[0].append(self.acceleration[0]) \n",
    "                self.all_accelerations[1].append(self.acceleration[1])\n",
    "                self.all_accelerations[2].append(self.acceleration[2])\n",
    "                self.pending_status.append(1)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def set_status(self, status):\n",
    "        self.status = status\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def to_df(self):\n",
    "        '''Print Trajectory as Dataframe'''\n",
    "        df = pd.DataFrame(columns = ['X_box', 'Y_box', 'Z_box', 'length_box', 'width_box', 'height_box', 'angle_box', 'camera'])\n",
    "        for i, j in enumerate(self.objects):\n",
    "            append_df = j.to_df()\n",
    "            append_df['frame'] = self.frames[i]       \n",
    "            df = df.append(append_df)\n",
    "            df.reset_index(inplace=True, drop=True)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def set_Kalman_Filter(self, model_type='ca', x0=None, dt=dt):\n",
    "        \"\"\"Initialize Kalman Filter object for the track\"\"\"\n",
    "        if x0 is None:\n",
    "            x0 = np.array([0, 0.5, 0.2, 0, 0.5, 0.2, 0, 0.5, 0.2]) # dummy object\n",
    "        if model_type == 'ca':\n",
    "            self.filter = KalmanFilter (dim_x=9, dim_z=3)\n",
    "            self.filter.x = np.array([x0.x, 0.5, 0.2, x0.y, 0.5, 0.2, x0.z, 0.5, 0.2])\n",
    "            self.filter.F = linear_transition_matrix(dt)\n",
    "            self.filter.H = H\n",
    "            self.filter.P *= 0.1 \n",
    "            self.filter.Q = np.eye(9) * 0.005 \n",
    "            self.filter.R = np.diag(np.array([0.5, 0.2, 0.05]))* 0.001\n",
    "            \n",
    "    def update_Kalman_Filter(self, y):\n",
    "        \"\"\"Perform Kalman Filter update with observed data y\"\"\"\n",
    "        y = np.array(y)\n",
    "        self.filter.update(y)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"ID: %d, status: %s, x: %f, y:%f, z:%f, new_time: %f, pending_time: %f, objects_count: %d, frame_count: %d\"%(self.ID, self.status, self.x, self.y, self.z, self.new_time, self.pending_time, len(self.objects), len(self.frames))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"ID %d - TimeNew %d\\n - Last coords (%f,%f,%f)\" %(self.ID, self.new_time, self.x, self.y, self.z)\n",
    "    \n",
    "    \n",
    "    def detection_vs_filter(self):\n",
    "        plt.figure()\n",
    "        plt.title('Detections vs Filter for Track: '+ str(self.ID))\n",
    "        abscissa = [pos[0] for pos in self.all_positions ]\n",
    "        ordinate = [pos[1] for pos in self.all_positions ]\n",
    "        plt.ylim((np.min(ordinate)-5,np.max(ordinate)+5))\n",
    "        plt.xlim((np.min(abscissa)-5,np.max(abscissa)+5))\n",
    "        plt.scatter(abscissa[0], ordinate[0], color = 'r')\n",
    "        plt.plot(abscissa, ordinate, color = 'r', label = 'Filter')\n",
    "        plt.scatter(abscissa[-1], ordinate[-1], color = 'r')\n",
    "        abscissa = [pos.x for pos in self.objects]\n",
    "        ordinate = [pos.y for pos in self.objects]\n",
    "        plt.scatter(abscissa[0], ordinate[0], color = 'b')\n",
    "        plt.plot(abscissa, ordinate, color = 'b', label = 'Detection')\n",
    "        plt.scatter(abscissa[-1], ordinate[-1], color = 'b')\n",
    "        \n",
    "        plt.legend()\n",
    "        return\n",
    "    \n",
    "    def visualize_trajectory(self, figsize = None , s = 100):\n",
    "        \"\"\" Input camera file, frame index and size of dot in the picture (default is 100) \"\"\"\n",
    "        \n",
    "        frame_idx = self.frames[-1] #control if this can be removed\n",
    "        camera_n = int(self.objects[-1].camera)\n",
    "        matches = { \n",
    "            109: hdf5data_109,\n",
    "            130: hdf5data_130,\n",
    "            142: hdf5data_142,\n",
    "            143: hdf5data_143\n",
    "                    }\n",
    "        camera = matches[camera_n]\n",
    "        \n",
    "        frame = camera['Sequence'][str(frame_idx)]\n",
    "\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "\n",
    "            #for point in self.all_positions:\n",
    "        for point in self.all_positions:\n",
    "\n",
    "            world_pos = np.array(point)\n",
    "            fin_pos = convert_to_image_space(world_pos, camera['TMatrixWorldToCam'], camera['ProjectionMatrix'])\n",
    "            x_list.append(fin_pos[0])\n",
    "            y_list.append(fin_pos[1])\n",
    "\n",
    "        # Show image\n",
    "        a = np.asarray(frame['Image'])\n",
    "\n",
    "        if figsize is not None: \n",
    "            plt.figure(figsize = figsize)\n",
    "\n",
    "        plt.imshow(a, cmap = 'gist_gray', zorder = 1)\n",
    "        plt.scatter(x_list, y_list, s = s, color = 'hotpink', zorder = 3)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def visualize_velocities(self):\n",
    "        fig, ((ax0, ax1), (ax2, axv)) = plt.subplots(2,2)\n",
    "        \n",
    "        ax0.scatter(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[0], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax0.plot(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[0], c='black', lw=0.5)\n",
    "        ax0.set_title('vx')\n",
    "\n",
    "        ax1.scatter(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[1], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax1.plot(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[1], c='black', lw=0.5)\n",
    "        ax1.set_title('vy')\n",
    "        \n",
    "        ax2.scatter(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[2], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax2.plot(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[2], c='black', lw=0.5)\n",
    "        ax2.set_title('vz')\n",
    "        \n",
    "        vel = np.sqrt(np.array(self.all_velocities[0])**2+ np.array(self.all_velocities[1])**2+ np.array(self.all_velocities[2])**2)\n",
    "        axv.scatter(np.arange(len(self.all_velocities[0]))*dt, vel, c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        axv.plot(np.arange(len(self.all_velocities[0]))*dt, vel, c='black', lw=0.5)\n",
    "        axv.set_title('|v|')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def visualize_accelerations(self):\n",
    "        fig, ((ax0, ax1), (ax2, axv)) = plt.subplots(2,2)\n",
    "        \n",
    "        ax0.scatter(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[0], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax0.plot(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[0], c='black', lw=0.5)\n",
    "        ax0.set_title('ax')\n",
    "\n",
    "        ax1.scatter(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[1], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax1.plot(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[1], c='black', lw=0.5)\n",
    "        ax1.set_title('ay')\n",
    "        \n",
    "        ax2.scatter(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[2], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax2.plot(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[2], c='black', lw=0.5)\n",
    "        ax2.set_title('az')\n",
    "        \n",
    "        acc = np.sqrt(np.array(self.all_accelerations[0])**2+ np.array(self.all_accelerations[1])**2+ np.array(self.all_accelerations[2])**2)\n",
    "        axv.scatter(np.arange(len(self.all_accelerations[0]))*dt, acc, c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        axv.plot(np.arange(len(self.all_accelerations[0]))*dt, acc, c='black', lw=0.5)\n",
    "        axv.set_title('|a|')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function needed to join cameras\n",
    "\n",
    "def custom_prob(obj1, obj2):\n",
    "    \n",
    "    #Mean is center of obj1, std dimension of the boxes, we multiply cov by a coefficient related to distance in time\n",
    "    time_coef = 0.05 #0.05 Ok with 0.06 as timestep, probably better 0.03 with 0.08\n",
    "    mean = obj1[0:3]\n",
    "    std = obj1[3:6]\n",
    "    cov = np.diag(np.power(std,2)) * np.exp(np.abs(obj1[7] - obj2[7])/time_coef, dtype = np.float64)\n",
    "\n",
    "    x = obj2[:3]\n",
    "\n",
    "    m_dist_x = np.dot((x-mean).transpose(),np.linalg.inv(cov))\n",
    "    m_dist_x = np.dot(m_dist_x, (x-mean))\n",
    "    \n",
    "    dist = 1-stats.chi2.cdf(m_dist_x, 3)\n",
    "    \n",
    "    #If objs belong to same camera -> 0 prob of being same one (consider to comment this rows)\n",
    "    if dist != 1 and obj1[9] == obj2[9] and obj1[7] == obj2[7]:\n",
    "        return 0\n",
    "    \n",
    "    return dist\n",
    "\n",
    "def unify(frame):\n",
    "    \n",
    "    #Convert Frame to array\n",
    "    frame_values = frame.iloc[:,:].values\n",
    "\n",
    "    #Compute probabilities\n",
    "    dists = cdist(frame_values, frame_values, custom_prob)\n",
    "    \n",
    "    #Create index array\n",
    "    index = np.empty(shape = (len(frame.index)))\n",
    "    index[:] = np.nan\n",
    "    \n",
    "    #Compute first argmax\n",
    "    argmax = np.unravel_index(dists.argmax(), dists.shape)\n",
    "    max_value = np.max(dists) \n",
    "    \n",
    "    #Cycle on maxima\n",
    "    while max_value > 0.35:\n",
    "    \n",
    "        if argmax[0] == argmax[1]:\n",
    "            dists[argmax] = -1\n",
    "\n",
    "        if argmax[0] != argmax[1]:\n",
    "            if dists[argmax[0], argmax[1]] > 0.8 or (dists[argmax[0], argmax[1]] > 0.5 and dists[argmax[1], argmax[0]] > 0.1):\n",
    "                if np.isnan(index[argmax[1]]):\n",
    "                    if np.isnan(index[argmax[0]]):\n",
    "                        index[argmax[0]] = argmax[0]\n",
    "                    index[argmax[1]] = index[argmax[0]]\n",
    "            dists[argmax] = -1\n",
    "    \n",
    "        argmax = np.unravel_index(dists.argmax(), dists.shape)\n",
    "        max_value = dists[argmax]\n",
    "\n",
    "    #Fill index vectors\n",
    "    for i in range(index.shape[0]):\n",
    "        if np.isnan(index[i]):\n",
    "            index[i] = i\n",
    "    \n",
    "    #Add index column\n",
    "    frame['object_index'] = index\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Methods to compute IoU and associate boxes through IoU\n",
    "\n",
    "def belongs_to(point, box, isdf=False):\n",
    "    \"\"\"Utility function that returns true if the point is found within the box, false otherwise\"\"\"\n",
    "    \n",
    "    if isdf:\n",
    "        center = box[['X_box', 'Y_box', 'Z_box']].to_numpy().flatten()\n",
    "        point = np.array([i for i in point]) - center\n",
    "        anti_rotation_matrix = np.array([[np.cos(-box['angle_box'].to_numpy()[0]), -np.sin(-box['angle_box'].to_numpy()[0]), 0], \n",
    "                            [np.sin(-box['angle_box'].to_numpy()[0]), np.cos(-box['angle_box'].to_numpy()[0]), 0], \n",
    "                            [0,0,1]])\n",
    "        rot_point = anti_rotation_matrix.dot(point)\n",
    "        \n",
    "        if np.abs(rot_point[0])<box['length_box'].to_numpy()/2 and np.abs(rot_point[1])<box['width_box'].to_numpy()/2 and np.abs(rot_point[2])<box['height_box'].to_numpy()/2:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    center = np.array([i for i in box[0]])\n",
    "    point = np.array([i for i in point]) - center\n",
    "    anti_rotation_matrix = np.array([[np.cos(-box[4]), -np.sin(-box[4]), 0], \n",
    "                            [np.sin(-box[4]), np.cos(-box[4]), 0], \n",
    "                            [0,0,1]])\n",
    "    rot_point = anti_rotation_matrix.dot(point)\n",
    "    \n",
    "    if np.abs(rot_point[0])<box[1]/2 and np.abs(rot_point[1])<box[2]/2 and np.abs(rot_point[2])<box[3]/2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def compute_approx_IoU(box1, box2, attempts=100): \n",
    "    \"\"\"Compute an approximated IoU between two boxes with a Monte Carlo approach\"\"\"\n",
    "\n",
    "    # store measures in meaningful variables\n",
    "    pos1 = box1[['X_box', 'Y_box', 'Z_box']].to_numpy().flatten()\n",
    "    pos2 = box2[['X_box', 'Y_box', 'Z_box']].to_numpy().flatten()\n",
    "    length1 = box1['length_box'].to_numpy()[0]\n",
    "    width1 = box1['width_box'].to_numpy()[0]\n",
    "    height1 = box1['height_box'].to_numpy()[0]\n",
    "    length2 = box2['length_box'].to_numpy()[0]\n",
    "    width2 = box2['width_box'].to_numpy()[0]\n",
    "    height2 = box2['height_box'].to_numpy()[0]\n",
    "    diag1 = np.sqrt(length1**2+width1**2+height1**2)\n",
    "    diag2 = np.sqrt(length2**2+width2**2+height2**2)\n",
    "    rotation_matrix1 = np.array([[np.cos(box1['angle_box'].to_numpy())[0], -np.sin(box1['angle_box'].to_numpy()[0]), 0], \n",
    "                            [np.sin(box1['angle_box'].to_numpy()[0]), np.cos(box1['angle_box'].to_numpy()[0]), 0], \n",
    "                            [0,0,1]])\n",
    "    rotation_matrix2 = np.array([[np.cos(box2['angle_box'].to_numpy()[0]), -np.sin(box2['angle_box'].to_numpy()[0]), 0], \n",
    "                            [np.sin(box2['angle_box'].to_numpy()[0]), np.cos(box2['angle_box'].to_numpy()[0]), 0], \n",
    "                            [0,0,1]])\n",
    "    \n",
    "    # return 0 if boxes are non-overlapping\n",
    "    if np.sqrt((pos1[0]-pos2[0])**2+(pos1[1]-pos2[1])**2+(pos1[2]-pos2[2])**2)>max(diag1, diag2):\n",
    "        return 0\n",
    "    \n",
    "    # if an overlap exists, estimate IoU by drawing random points in each box and checking how many also belong to the other\n",
    "    intersection = 0\n",
    "    \n",
    "    for i in range(attempts):\n",
    "        u = np.random.uniform(-1,1,size=3) * np.array([length1,width1,height1])/2 \n",
    "        u = rotation_matrix1.dot(u)\n",
    "        if belongs_to(u + np.array([i for i in pos1]), box2, True):\n",
    "            intersection +=1\n",
    "        u = np.random.uniform(-1,1,size=3) * np.array([length2,width2,height2])/2 \n",
    "        u = rotation_matrix2.dot(u)\n",
    "        if belongs_to(u + np.array([i for i in pos2]), box1, True):\n",
    "            intersection +=1\n",
    "    return intersection/2/attempts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions used to associate tracks and detections\n",
    "\n",
    "def find_subsequent_boxes(track_list1, track_list2):\n",
    "    \"\"\"\n",
    "    Returns a numpy array of the best matches of boxes in track_list2 for boxes in track_list1, if any.\n",
    "    If no IoU above a fixed threshold is found, -1 is assigned.\n",
    "    \"\"\"\n",
    "    \n",
    "    iou_vals = np.zeros(shape=(len(track_list1), len(track_list2)))\n",
    "    \n",
    "    for i in range(len(track_list1)):\n",
    "        for j in range(len(track_list2)):\n",
    "\n",
    "            df1 = track_list1[i].to_df()\n",
    "            last_frame = df1.frame.max()\n",
    "            iou = compute_approx_IoU(df1[df1.frame==last_frame],track_list2[j].to_df())\n",
    "            iou_vals[i][j] = iou\n",
    "        \n",
    "    return iou_vals\n",
    "\n",
    "def track_detection_association(track_coord, obj_coord):\n",
    "    ''' Function for computing the euclidean distance between detections and predicted track positions'''\n",
    "    \n",
    "    dists = cdist(track_coord, obj_coord, 'euclidean') \n",
    "\n",
    "    return dists\n",
    "\n",
    "### Perform association of objects in previous and next frame\n",
    "\n",
    "def associate(tracks, obj_list, frame_index):\n",
    "    \n",
    "    all_tracks = tracks.items()\n",
    "    all_tracks = np.array([track for cat, trs in all_tracks if cat in ['Active', 'New', 'Pending'] for track in trs])\n",
    "    track_coord = np.array([[t.x, t.y, t.z] for t in all_tracks]) \n",
    "    track_indices = np.array([t.ID for t in all_tracks])\n",
    "    \n",
    "    if track_coord.size and len(obj_list) > 0:\n",
    "        \n",
    "        # explore with iou\n",
    "        \n",
    "        iou_values = find_subsequent_boxes(all_tracks, obj_list)\n",
    "\n",
    "        obj_coord = [(obj.x, obj.y, obj.z) for obj in obj_list]\n",
    "        dist_values = track_detection_association(track_coord, obj_coord)\n",
    "        \n",
    "        complete_dists = 0.1 * (1-iou_values) + 0.9 * dist_values\n",
    "        \n",
    "        associations = visiting_algorithm(complete_dists,len(all_tracks))\n",
    "\n",
    "        for index, ass in enumerate(associations):\n",
    "            if ass == -1:\n",
    "                all_tracks[index].update(None, frame_index)\n",
    "            else:\n",
    "                all_tracks[index].update(obj_list[ass], frame_index)\n",
    "        \n",
    "        assigned = np.where(associations != -1)\n",
    "        associations = associations[assigned]\n",
    "\n",
    "        obj_list = np.delete(obj_list, associations, axis = 0)\n",
    "\n",
    "    return obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visiting_algorithm(complete_dists, n_tracks):\n",
    "    best_dist = complete_dists.min()\n",
    "    associations = - np.ones(shape = n_tracks, dtype = np.int8)\n",
    "    object_associations = complete_dists.argmin(axis = 0)\n",
    "    best_dists_obj = complete_dists.min(axis = 0)\n",
    "    threshold = best_dist + max_dist_threshold\n",
    "    \n",
    "    object_associations[best_dists_obj > threshold] = -1\n",
    "    \n",
    "    dict_ass = {}\n",
    "    for index in range(len(associations)):\n",
    "        correspondences = np.where(object_associations==index)[0]\n",
    "        dict_ass[index] = correspondences\n",
    "        \n",
    "    \n",
    "    \n",
    "    keep_going = True\n",
    "    while keep_going:\n",
    "        \n",
    "        keep_going = False\n",
    "        for index in range(n_tracks):\n",
    "            correspondences = dict_ass[index]\n",
    "            if (np.size(correspondences) > 1):\n",
    "                keep_going = True\n",
    "                \n",
    "                best_sub_dists = best_dists_obj[correspondences]\n",
    "                # print(best_sub_dists)\n",
    "                idx = np.argmin(best_sub_dists)\n",
    "            \n",
    "                dict_ass[index] = correspondences[idx]\n",
    "                \n",
    "                # associations[index] = correspondences[idx]\n",
    "                for elem in correspondences: \n",
    "                    if (elem != correspondences[idx]):\n",
    "                        new_ass = find_seq_min(complete_dists, elem, index)\n",
    "                        new_ass_dist = complete_dists[new_ass][elem]\n",
    "                        best_dists_obj[elem] = new_ass_dist \n",
    "                        if (new_ass_dist < threshold):\n",
    "                            dict_ass[new_ass] = np.append(dict_ass[new_ass],elem)\n",
    "            \n",
    "            elif (np.size(correspondences) == 1) :\n",
    "                associations[index] = correspondences\n",
    "    \n",
    "    return associations \n",
    "\n",
    "\n",
    "def find_seq_min(complete_dists, elem, index):\n",
    "    \n",
    "    dist_copy = copy(complete_dists)\n",
    "    to_change = dist_copy[:,elem] <= dist_copy[index,elem]\n",
    "    dist_copy[to_change,elem] = np.inf \n",
    "    pos = np.argmin(dist_copy[:,elem])\n",
    "    return pos \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class tracker\n",
    "\n",
    "class Tracker:\n",
    "    \n",
    "    def __init__(self, dfs):\n",
    "        self.tracks = {'Active': [], 'Pending': [], 'Inactive': [], 'New': [], 'Removed': []}\n",
    "        self.dataframe = concatenate_dfs(dfs, ['frame', 'camera'])\n",
    "        self.track_id = 0 \n",
    "        self.time = -0.06\n",
    "        self.current_objects = pd.DataFrame()\n",
    "        self.frame_index = -1\n",
    "        \n",
    "    \n",
    "    def update_tracks(self):\n",
    "        ''' Update the status of the tracks, moving them to the different lists'''\n",
    "        for tr in self.tracks['New'][::-1]:\n",
    "            if tr.status != 'New':\n",
    "                self.tracks['New'].remove(tr)\n",
    "                self.tracks[tr.status].append(tr)\n",
    "        \n",
    "        for tr in self.tracks['Pending'][::-1]:\n",
    "            if tr.status != 'Pending':\n",
    "                self.tracks['Pending'].remove(tr)\n",
    "                self.tracks[tr.status].append(tr)\n",
    "        \n",
    "        for tr in self.tracks['Active'][::-1]:\n",
    "            if tr.status != 'Active':\n",
    "                self.tracks['Active'].remove(tr)\n",
    "                self.tracks[tr.status].append(tr)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def next_step(self):\n",
    "        '''Proceed with next time step analysis of frames'''\n",
    "        self.frame_index += 1\n",
    "        self.time += dt\n",
    "        self.current_objects = self.dataframe[np.abs(self.dataframe['elapsed_time']-self.time)<=dt/2]# very unlikely one happens to be EXACTLY in the middle\n",
    "        self.merge_collisions()\n",
    "        self.analyze_frame()\n",
    "        \n",
    "    \n",
    "    def analyze_frame(self):\n",
    "        ''' Analyze frame creating or updating trajectories'''\n",
    "        \n",
    "        frame = self.current_objects \n",
    "        obj_list = []\n",
    "        \n",
    "        # Extract all the detections in the frame\n",
    "        for index, row in frame.iterrows():\n",
    "            obj = Object(row['X_box'], row['Y_box'], row['Z_box'], row['length_box'], \n",
    "                         row['width_box'], row['height_box'], row['angle_box'], row['camera'])\n",
    "            obj_list.append(obj)\n",
    "\n",
    "        obj_list = np.array(obj_list)\n",
    "        \n",
    "        # Perform associations\n",
    "        obj_list = associate( self.tracks, obj_list, self.frame_index)\n",
    "        \n",
    "        # Check status of all tracks\n",
    "        self.update_tracks()        \n",
    "        \n",
    "        #Create new tracks for not linked objects\n",
    "        for obj in obj_list:\n",
    "            tr = Track(self.track_id, obj, self.frame_index)\n",
    "            self.track_id += 1\n",
    "            self.tracks['New'].append(tr)\n",
    "            # self.track_list[self.track_id] = []\n",
    "            # self.track_list.append('New')\n",
    "        \n",
    "        \n",
    "    def merge_collisions(self):\n",
    "        \n",
    "        if 'credibility_level' not in self.current_objects:\n",
    "            credibility_level(self.current_objects)\n",
    "        \n",
    "        \n",
    "        self.current_objects = self.current_objects[self.current_objects['credibility_level'] != 0.25]\n",
    "        \n",
    "        unify(self.current_objects)\n",
    "        labeled_df = self.current_objects\n",
    "        \n",
    "        if np.all(labeled_df.groupby(['object_index']).count()==1):\n",
    "            return \n",
    "        \n",
    "        labeled_df.loc[:,~labeled_df.columns.isin(['credibility_level', 'camera', 'object_index'])] = labeled_df.loc[:,~labeled_df.columns.isin(['credibility_level', 'camera', 'object_index'])].multiply(labeled_df.credibility_level, axis='index')\n",
    "        cameras = labeled_df.sort_values(by=['object_index', 'credibility_level'], ascending=[True,False]).groupby(['object_index']).head(1)[['object_index','camera']].set_index('object_index')\n",
    "        labeled_df = labeled_df.groupby(['object_index']).sum()\n",
    "        labeled_df = labeled_df.divide(labeled_df.credibility_level, axis='index')\n",
    "        labeled_df = labeled_df.drop(['credibility_level'], axis=1)\n",
    "        \n",
    "        labeled_df['frame'] = self.frame_index\n",
    "        try:\n",
    "            labeled_df['camera'] = cameras\n",
    "        except: \n",
    "            print(len(cameras.values), len(labeled_df['camera']))\n",
    "        \n",
    "        self.current_objects = labeled_df\n",
    "        self.current_objects['elapsed_time'] = self.time\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def return_track(self,id_):\n",
    "        for t_l in self.tracks.values():\n",
    "            for t in t_l: \n",
    "                if t.ID == id_ : \n",
    "                    return t\n",
    "        print('Track with ID ', id_, ' not found')\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def iterate_for(self,n_iter):\n",
    "        for i in range(n_iter):\n",
    "            self.next_step()\n",
    "            self.summary_track_types(i)\n",
    "        \n",
    "        cmap = plt.get_cmap('tab20')\n",
    "        num = len(cmap.colors)\n",
    "        colors = [cmap(i) for i in np.linspace(0,1,num)]\n",
    "        self.print_tracks(colors, num)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def print_tracks(self,colors,num_cols):\n",
    "        plt.figure()\n",
    "        plt.title(\"plot of Active and New tracks\")\n",
    "        for t in self.tracks['Active']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [-pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], color = colors[t.ID%num_cols])\n",
    "            \n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], color = colors[t.ID%num_cols])\n",
    "            \n",
    "        for t in self.tracks['New']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [-pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], color = colors[t.ID%num_cols])\n",
    "            \n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], color = colors[t.ID%num_cols])\n",
    "        plt.figure()\n",
    "        plt.title(\"plot of Pending and Inactive tracks\")\n",
    "        for t in self.tracks['Inactive']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [-pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], marker = \"*\", color = colors[t.ID%num_cols])\n",
    "            \n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], marker = \"*\", color = colors[t.ID%num_cols])\n",
    "            \n",
    "        for t in self.tracks['Pending']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [-pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], color = colors[t.ID%num_cols])\n",
    "            \n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], color = colors[t.ID%num_cols])\n",
    "        \n",
    "        return\n",
    "        \n",
    "    \n",
    "    def summary_track_types(self, n ):\n",
    "        print(\"-------------------------------- Iteration N° \", n+1, \"--------------------------------\")\n",
    "        print(\"Active tracks: \", len(self.tracks['Active']), 4*\" \", \"New tracks: \", len(self.tracks['New']),\n",
    "              4*\" \", \"Pending tracks: \", len(self.tracks['Pending']), 4*\" \", \"Removed tracks: \", \n",
    "              len(self.tracks['Removed']) ,4*\" \", \"Inactive tracks: \", len(self.tracks['Inactive']) )\n",
    "        print(\"\\n\")\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def plot_individual_track(self, ID):\n",
    "        for cat, trs in self.tracks.items():\n",
    "            for track in trs:\n",
    "                if track.ID == ID:\n",
    "                    \n",
    "                    track.visualize_trajectory(figsize=(12,12), s=10)\n",
    "                    return\n",
    "        print(\"Object not found\")\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo and performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tracker, analyze some frames\n",
    "TrackTrack = Tracker([df_109,df_130,df_142,df_143])\n",
    "TrackTrack.iterate_for(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tracks do we have?\n",
    "TrackTrack.track_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot all the tracks\n",
    "\n",
    "for ID in range(TrackTrack.track_id):\n",
    "    t = TrackTrack.return_track(ID)\n",
    "    print(\"Track \" + str(t.ID) + \", Status: \" + t.status )\n",
    "    TrackTrack.plot_individual_track(ID)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['Active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['New']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['Pending']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['Inactive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['Removed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract track with specific ID\n",
    "t = TrackTrack.return_track(7)\n",
    "t.frames\n",
    "t.objects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
