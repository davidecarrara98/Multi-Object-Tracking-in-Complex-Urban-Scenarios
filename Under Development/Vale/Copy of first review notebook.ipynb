{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi object tracking in complex urban scenarios - Mid-term review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program of the day:\n",
    "\n",
    "1. Methods used\n",
    "2. Implementation\n",
    "3. Performance and demo\n",
    "\n",
    "Our main focus was to quickly deliver a fully working model, to be refined later on.\n",
    "\n",
    "1. Guided by literature, we adopted the following design choices:\n",
    " - a mixed distance based on _Intersection over Union_ of bounding boxes + _Kalman Filter_ predictions for **track - detection association** (combining different literature sources such as \"Multiple Object Tracking with Motion and Appearance Cues\", Li, Mu and Liu, and \"Simple online and realtime tracking with a deep association metric\", Wojke, Bewley and Paulus)\n",
    " - to **estimate motion**, the linear version of Kalman Filter, with a model of _Constant Acceleration_ (\"Comparison and Evaluation of Advanced Motion Models for Vehicle Tracking\", Schubert, Richter and Wanielik)\n",
    " - to tackle the **asynchronicity of measures** from the four sensors, a merge based on a _Gaussian model of distance_ \n",
    " \n",
    " \n",
    "2. Some first manipulations included:\n",
    "  - converting the data format to **Pandas DataFrames**, quite flexible and optimized for performing row-wise operations, in our case allowing us to treat detections in batch. In particular, in a real context, we might process data arriving every _deltaT,_ a constant time chosen so to reflect best the behavior of the sensors. In our case an internal clock of 0.08 seconds was set.\n",
    "  - creating some **visual tools** to observe *centers of detections, bounding boxes, 2D movement from above* \n",
    "  - designing **3 general classes** to represent the entities in our problem - these may be later enriched through inheritance whenever more information is available. The classes represent _Object, Track, Tracker_ , where the latter is a wrapper that takes care of storing, updating information when new data comes and some visualization tools.\n",
    "  - processing incoming data so to **align detections** from different sensors and **merge observations** likely referring to the same object. A measure of reliability of detections is included, based on the absolute position with respect to the sensor. \n",
    "  \n",
    "  The details can be observed below.\n",
    "  \n",
    "  \n",
    "3. Performance is still to be defined properly. As of 12 December 2021, the main performance feedback has been visual.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed \n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '../Data/data_109.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18204/888903984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# upload data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhdf5data_109\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/data_109.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhdf5data_130\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/data_130.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhdf5data_142\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/data_142.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhdf5data_143\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/data_143.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    443\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[0;32m    444\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '../Data/data_109.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# upload data \n",
    "hdf5data_109 = h5py.File('../Data/data_109.h5', 'r')\n",
    "hdf5data_130 = h5py.File('../Data/data_130.h5', 'r')\n",
    "hdf5data_142 = h5py.File('../Data/data_142.h5', 'r')\n",
    "hdf5data_143 = h5py.File('../Data/data_143.h5', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer data into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_rows_detections(detections, returndf):\n",
    "    \n",
    "    coord_detections = [np.array(vals[0].tolist()) for vals in detections]\n",
    "    coord_detections = np.vstack(coord_detections)\n",
    "        \n",
    "    length_box = [vals[1] for vals in detections]\n",
    "    width_box = [vals[2] for vals in detections]\n",
    "    height_box = [vals[3] for vals in detections]\n",
    "    angle_box = [vals[4] for vals in detections]\n",
    "    \n",
    "    returndf[\"X_box\"] = coord_detections[:,0]\n",
    "    returndf[\"Y_box\"] = coord_detections[:,1]\n",
    "    returndf[\"Z_box\"] = coord_detections[:,2]\n",
    "    returndf[\"length_box\"], returndf[\"width_box\"], returndf[\"height_box\"] = length_box, width_box, height_box\n",
    "    returndf[\"angle_box\"] = angle_box\n",
    "    \n",
    "    return returndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_detections(h5data,camera = None):\n",
    "    \n",
    "    timestamps = h5data['Timestamp']\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for c, t in enumerate(timestamps):\n",
    "        \n",
    "        append_df = pd.DataFrame()\n",
    "        \n",
    "        d = h5data['Sequence'][str(c)]\n",
    "        detection = np.asarray(d['Detections'])\n",
    "        \n",
    "        if detection.size:\n",
    "            append_df = fill_rows_detections(detection, append_df)\n",
    "            append_df['timestamp'] = t\n",
    "            append_df['frame'] = c\n",
    "        \n",
    "            if camera is not None:\n",
    "                append_df['camera'] = camera\n",
    "        \n",
    "            df = df.append(append_df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_109 = df_detections(hdf5data_109, 109)\n",
    "df_109.reset_index(inplace=True, drop=True)\n",
    "df_130 = df_detections(hdf5data_130, 130)\n",
    "df_130.reset_index(inplace=True, drop=True)\n",
    "df_142 = df_detections(hdf5data_142, 142)\n",
    "df_142.reset_index(inplace=True, drop=True)\n",
    "df_143 = df_detections(hdf5data_143, 143)\n",
    "df_143.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_dfs(dfs, sort_cols):\n",
    "    \n",
    "    df_to_concat = dfs\n",
    "    df_complete = pd.concat(df_to_concat)\n",
    "    df_complete.sort_values(by = sort_cols, inplace = True)\n",
    "    df_complete.reset_index(inplace=True, drop=True)\n",
    "    df_complete['elapsed_time'] = df_complete['timestamp']-df_complete['timestamp'].min()\n",
    "    \n",
    "    return df_complete\n",
    "\n",
    "df_complete = concatenate_dfs([df_109,df_130,df_142,df_143] , ['frame', 'camera'])\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add reliability of measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define coordinate transformation useful to find credibility levels\n",
    "def convert_to_image_space ( coordinates , world2cam , cam2im ):\n",
    "    \"\"\" Input single set of coordinatetes \"\"\"\n",
    "    coord_4 = np.ones (4)\n",
    "    coord_4[0:3] = coordinates\n",
    "    cams_coord = ( np.matmul( world2cam , coord_4.T )).T\n",
    "    cams_coord_4 = np.ones(4)\n",
    "    \n",
    "    cams_coord_4 [0:3] = cams_coord [0:3]\n",
    "    ims_coord = ( np . matmul ( cam2im , cams_coord_4 .T )). T\n",
    "    # Divide by z coordinate for some reason\n",
    "    ims_coord [0] = ims_coord [0]/ ims_coord [2]\n",
    "    ims_coord [1] = ims_coord [1]/ ims_coord [2]\n",
    "    ims_coord = ims_coord [0:2]\n",
    "    \n",
    "    return ( ims_coord )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credibility_level(df):\n",
    "    df['credibility_level'] = np.zeros(shape = len(df.index))\n",
    "    for ind,row in df.iterrows():\n",
    "        coordinates = row[['X_box','Y_box','Z_box']]\n",
    "        \n",
    "        if row['camera'] == 109: \n",
    "            df.at[ind,'credibility_level'] = level_affidability_109(coordinates);\n",
    "            \n",
    "                    \n",
    "        elif row['camera'] == 130:\n",
    "            df.at[ind,'credibility_level'] = level_affidability_130(coordinates);\n",
    "            \n",
    "            \n",
    "        elif row['camera'] == 142:\n",
    "            df.at[ind,'credibility_level'] = level_affidability_142(coordinates);\n",
    "         \n",
    "        \n",
    "        if row['camera'] == 143:\n",
    "            df.at[ind,'credibility_level'] = level_affidability_143(coordinates);\n",
    "        \n",
    "\n",
    "                \n",
    "def level_affidability_109(coordinates):\n",
    "    world2cam = hdf5data_109['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_109['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    sloap1 = (-250 + 121.374145)/(600-296.40511363)\n",
    "    sloap2 = 8/65\n",
    "    if - img_coord[1] <= sloap1*(img_coord[0] - 600) - 250:\n",
    "        return 1\n",
    "    elif - img_coord[1] <= sloap2*(img_coord[0]) - 180:\n",
    "        return 0.75\n",
    "    else:\n",
    "        return 0.25\n",
    "\n",
    "    \n",
    "def level_affidability_130(coordinates):\n",
    "    world2cam = hdf5data_130['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_130['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    if (img_coord[0] <= 630) & (img_coord[1] >= 100):\n",
    "        return 1\n",
    "    elif (img_coord[0] <= 560) & (img_coord[0] >= 420):\n",
    "        return 0.25\n",
    "    else: \n",
    "        return 0.5\n",
    "    \n",
    "\n",
    "    \n",
    "def level_affidability_142(coordinates):\n",
    "    world2cam = hdf5data_142['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_142['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    if (img_coord[0] <= 600) & (img_coord[0] >= 380) & (img_coord[1] <= 120):\n",
    "        return 0.25\n",
    "    elif img_coord[1] > 120:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0.75\n",
    "\n",
    "    \n",
    "def level_affidability_143(coordinates):\n",
    "    world2cam = hdf5data_143['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_143['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    if (img_coord[0] >= 410) & (img_coord[1] <= 120):\n",
    "        return 0.25\n",
    "    if (img_coord[0] < 410) & (img_coord[1] <= 120):\n",
    "        return 0.5\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credibility_level(df_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_frame_detections ( camera, frame_idx, figsize = None , s = 100):\n",
    "    \"\"\" Input camera file, frame index and size of dot in the picture (default is 100) \"\"\"\n",
    "    \n",
    "    frame = camera['Sequence'][str(frame_idx)]\n",
    "    detected_points = np.asarray(frame['Detections'])\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for point in detected_points:\n",
    "    \n",
    "        world_pos = np.array(point[0].tolist())\n",
    "        fin_pos = convert_to_image_space(world_pos, camera['TMatrixWorldToCam'], camera['ProjectionMatrix'])\n",
    "        x_list.append(fin_pos[0])\n",
    "        y_list.append(fin_pos[1])\n",
    "\n",
    "    # Show image\n",
    "    a = np.asarray(frame['Image'])\n",
    "    \n",
    "    if figsize is not None: \n",
    "        plt.figure(figsize = figsize)\n",
    "        \n",
    "    plt.imshow(a, cmap = 'gist_gray', zorder = 1)\n",
    "    plt.scatter(x_list, y_list, s = s, color = 'hotpink', zorder = 3)\n",
    "    \n",
    "    return\n",
    "\n",
    "def visualize_frame_boxes ( camera, frame_idx, figsize = None, s = 100):\n",
    "    \"\"\" Input camera file, frame index and size of dot in the picture (default is 100) \"\"\"\n",
    "    \n",
    "    frame = camera['Sequence'][str(frame_idx)]\n",
    "    detected_points = np.asarray(frame['Detections'])\n",
    "    \n",
    "    if figsize is not None: \n",
    "        plt.figure(figsize = figsize)\n",
    "        \n",
    "    \n",
    "    for point in detected_points:\n",
    "        # first face \n",
    "        unrotated_vertex1 = np.array([+ point['Length']/2, + point['Width']/2, + point['Height']/2])\n",
    "        unrotated_vertex2 = np.array([+ point['Length']/2, + point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex3 = np.array([+ point['Length']/2, - point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex4 = np.array([+ point['Length']/2, - point['Width']/2, + point['Height']/2])\n",
    "        # second face \n",
    "        unrotated_vertex5 = np.array([- point['Length']/2, + point['Width']/2, + point['Height']/2])\n",
    "        unrotated_vertex6 = np.array([- point['Length']/2, + point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex7 = np.array([- point['Length']/2, - point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex8 = np.array([- point['Length']/2, - point['Width']/2, + point['Height']/2])\n",
    "        \n",
    "        \n",
    "        unrotated_vertex_list = [unrotated_vertex1, unrotated_vertex2, unrotated_vertex3, \n",
    "                                 unrotated_vertex4, unrotated_vertex5, unrotated_vertex6, \n",
    "                                 unrotated_vertex7, unrotated_vertex8]\n",
    "        \n",
    "        rotation_matrix = np.array([[np.cos(point['Angle']), -np.sin(point['Angle']), 0], \n",
    "                            [np.sin(point['Angle']), np.cos(point['Angle']), 0], \n",
    "                            [0,0,1]])\n",
    "        \n",
    "        rotated_vertex_list = np.array([rotation_matrix.dot(v) for v in unrotated_vertex_list])\n",
    "        rotated_vertex_list = rotated_vertex_list + np.array([point['Pos']['X'], point['Pos']['Y'], point['Pos']['Z']])\n",
    "        \n",
    "        vertex_im_list = [convert_to_image_space(v, camera['TMatrixWorldToCam'], camera['ProjectionMatrix']) for v in rotated_vertex_list]\n",
    "        \n",
    "        \n",
    "        combinations = [(i,i+1) for i in range(3)] + [(3,0)] + [(i,i+1) for i in range(4,7)] + [\n",
    "            (7,4)] + [(i,i+4) for i in range(4)]\n",
    "        \n",
    "        for (i,j) in combinations: \n",
    "            vertex_x_list = [vertex_im_list[i][0],vertex_im_list[j][0]]\n",
    "            vertex_y_list = [vertex_im_list[i][1],vertex_im_list[j][1]]\n",
    "            plt.plot(vertex_x_list, vertex_y_list, color = 'b', zorder = 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    visualize_frame_detections ( camera, frame_idx, s = s )\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def visualize_alldetections(df, frame_idx = None):\n",
    "    ''' Visualize all detections from above'''\n",
    "    if frame_idx is not None:\n",
    "        x = df['X_box'][df['frame'] == frame_idx]\n",
    "        y = df['Y_box'][df['frame'] == frame_idx]\n",
    "        display(df[df['frame'] == frame_idx])\n",
    "    \n",
    "    else:\n",
    "        x = df['X_box']\n",
    "        y = df['Y_box']\n",
    "        \n",
    "    plt.scatter(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_frame_detections(hdf5data_109,260, figsize = (12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_frame_boxes(hdf5data_109, 260, figsize = (12,12), s = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_alldetections(df_complete, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define some useful constants\n",
    "\n",
    "dt = 0.08\n",
    "new_time_threshold = 7\n",
    "active_time_threshold = 8\n",
    "speed_acc_window = 5\n",
    "H = np.array([[1.,0.,0., 0., 0., 0., 0., 0., 0.],[0.,0., 0.,1., 0., 0., 0., 0., 0.],[0.,0., 0., 0., 0., 0.,1., 0., 0.]])\n",
    "max_dist_threshold = 10\n",
    "\n",
    "\n",
    "def linear_transition_matrix(dt):\n",
    "    \"\"\"Returns matrix F of the Constant Acceleration model\"\"\"\n",
    "    return np.array([[1., dt, 0.5*dt**2, 0., 0., 0., 0., 0., 0.], [0, 1, dt, 0., 0., 0., 0., 0., 0. ], [0.,0.,1., 0., 0., 0., 0., 0., 0.],\n",
    "               [0.,0.,0.,1.,dt,0.5*dt**2,0.,0.,0.],[0.,0.,0.,0.,1.,dt,0.,0.,0.],[0.,0.,0.,0.,0.,1.,0.,0.,0.],\n",
    "               [0.,0.,0.,0.,0.,0.,1.,dt,0.5*dt**2],[0.,0.,0.,0.,0.,0.,0.,1.,dt], [0.,0.,0.,0.,0.,0.,0.,0.,1.]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class representing a single detection\n",
    "\n",
    "class Object:\n",
    "    def __init__(self, x, y, z, l, w, h, angle, camera):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.length = l\n",
    "        self.width = w\n",
    "        self.height = h\n",
    "        self.angle = angle\n",
    "        self.camera = camera\n",
    "        \n",
    "    def to_df(self):\n",
    "        \n",
    "        df = pd.DataFrame([[self.x, self.y, self.z, self.length, self.width, self.height, self.angle, self.camera]], \n",
    "                         columns = ['X_box', 'Y_box', 'Z_box', 'length_box', 'width_box', 'height_box', 'angle_box', 'camera'])\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"x: %f, y:%f, z:%f, length:%f, width:%f, height:%f, angle:%f, camera:%d \\n\" %(self.x, self.y, self.z, self.length, self.width, self.height, self.angle, self.camera)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"x: %f, y:%f, z:%f \\n\" %(self.x, self.y, self.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class representing the Tracks\n",
    "\n",
    "class Track:\n",
    "    \n",
    "    def __init__(self, ID, OBJ, FRAME, threshold = new_time_threshold):\n",
    "        self.ID = ID\n",
    "        self.status = 'New' \n",
    "        self.objects = [OBJ]\n",
    "        self.x, self.y, self.z = OBJ.x, OBJ.y, OBJ.z\n",
    "        self.frames = [FRAME]\n",
    "        self.velocity = [0.5, 0.5, 0.5]\n",
    "        self.acceleration = [0.2, 0.2, 0.2]\n",
    "        self.type = None\n",
    "        self.threshold = threshold\n",
    "        self.filter = None\n",
    "        self.new_time = 1\n",
    "        self.pending_time = 0\n",
    "        self.active_time = 0\n",
    "        self.all_positions = [[OBJ.x, OBJ.y, OBJ.z]]\n",
    "        \n",
    "        self.set_Kalman_Filter(x0 = OBJ)\n",
    "    \n",
    "    def update(self, OBJ, FRAME):\n",
    "        \"\"\"Performs different update routines based on the presence of an associated object or not, and the current status of the track\"\"\"\n",
    "        # predict next state through KF\n",
    "        self.filter.predict()\n",
    "        \n",
    "        # update with object\n",
    "        if OBJ is not None:\n",
    "            self.objects.append(OBJ)\n",
    "            self.frames.append(FRAME)\n",
    "            # update of a new trajectory - velocity and acceleration are estimated through sample averages of observed positions for improving the start conditions\n",
    "            if self.status == 'New':\n",
    "                self.x, self.y, self.z = OBJ.x, OBJ.y, OBJ.z\n",
    "                last_xs = np.array([obj.x for obj in self.objects])\n",
    "                last_ys = np.array([obj.y for obj in self.objects])\n",
    "                last_zs = np.array([obj.z for obj in self.objects])\n",
    "                if len(last_xs)>1:\n",
    "                    self.velocity[0] = np.mean(last_xs[1:]-last_xs[:-1]/dt)\n",
    "                    self.velocity[1] = np.mean(last_ys[1:]-last_ys[:-1]/dt)\n",
    "                    self.velocity[2] = np.mean(last_zs[1:]-last_zs[:-1]/dt)\n",
    "                if len(last_xs)>2:\n",
    "                    self.acceleration[0] = (last_xs[2:] - 2* last_xs[1:-1] + last_xs[:-2])[0]/(dt**2)\n",
    "                    self.acceleration[1] = (last_ys[2:] - 2* last_ys[1:-1] + last_ys[:-2])[0]/(dt**2)\n",
    "                    self.acceleration[2] = (last_zs[2:] - 2* last_zs[1:-1] + last_zs[:-2])[0]/(dt**2)\n",
    "                \n",
    "                self.filter.x = np.array([self.x,self.velocity[0], self.acceleration[0],\n",
    "                                          self.y,self.velocity[1], self.acceleration[1],\n",
    "                                          self.z,self.velocity[2], self.acceleration[2]])\n",
    "                self.new_time += 1\n",
    "                if self.new_time > self.threshold:\n",
    "                    self.status = 'Active'\n",
    "            else:\n",
    "                \n",
    "                # Kalman Filter is updated with observed values\n",
    "                self.update_Kalman_Filter(np.array([OBJ.x, OBJ.y, OBJ.z]))\n",
    "                \n",
    "                # for some active time keep using the sample average estimated velocity and acceleration to ensure KF has enough time to converge\n",
    "                if self.active_time < active_time_threshold: \n",
    "                    self.x, self.y, self.z = OBJ.x, OBJ.y, OBJ.z\n",
    "                    last_xs = np.array([obj.x for obj in self.objects[-speed_acc_window:]])\n",
    "                    last_ys = np.array([obj.y for obj in self.objects[-speed_acc_window:]])\n",
    "                    last_zs = np.array([obj.z for obj in self.objects[-speed_acc_window:]])\n",
    "                    \n",
    "                    self.velocity[0] = np.mean(last_xs[1:]-last_xs[:-1]/dt)\n",
    "                    self.velocity[1] = np.mean(last_ys[1:]-last_ys[:-1]/dt)\n",
    "                    self.velocity[2] = np.mean(last_zs[1:]-last_zs[:-1]/dt)\n",
    "                    \n",
    "                    self.acceleration[0] = (last_xs[2:] - 2* last_xs[1:-1] + last_xs[:-2])[0]/(dt**2)\n",
    "                    self.acceleration[1] = (last_ys[2:] - 2* last_ys[1:-1] + last_ys[:-2])[0]/(dt**2)\n",
    "                    self.acceleration[2] = (last_zs[2:] - 2* last_zs[1:-1] + last_zs[:-2])[0]/(dt**2)\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    self.x = self.filter.x[0]\n",
    "                    self.y = self.filter.x[3]\n",
    "                    self.z = self.filter.x[6]\n",
    "                    self.velocity = [self.filter.x[1], self.filter.x[4], self.filter.x[7]]\n",
    "                    self.acceleration = [self.filter.x[2], self.filter.x[5], self.filter.x[8]]\n",
    "                \n",
    "                \n",
    "                self.status = 'Active'\n",
    "            self.all_positions.append([self.x,self.y,self.z])\n",
    "        \n",
    "        # if no object is available, treat cases by either eliminating the trajectory or setting it as 'Pending'\n",
    "        if OBJ is None and self.status == 'New':\n",
    "            if self.new_time == 1: self.status = 'Removed'\n",
    "            else: self.new_time += 1\n",
    "        \n",
    "        if OBJ is None and self.status == 'Active':\n",
    "            self.status = 'Pending'\n",
    "            self.pending_time += 1\n",
    "        \n",
    "        if OBJ is None and self.status == 'Pending':\n",
    "            if self.pending_time == 5: self.status = 'Inactive'\n",
    "            else: self.pending_time += 1\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def set_status(self, status):\n",
    "        self.status = status\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def to_df(self):\n",
    "        '''Print Trajectory as Dataframe'''\n",
    "        df = pd.DataFrame(columns = ['X_box', 'Y_box', 'Z_box', 'length_box', 'width_box', 'height_box', 'angle_box', 'camera'])\n",
    "        for i, j in enumerate(self.objects):\n",
    "            append_df = j.to_df()\n",
    "            append_df['frame'] = self.frames[i]       \n",
    "            df = df.append(append_df)\n",
    "            df.reset_index(inplace=True, drop=True)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def set_Kalman_Filter(self, model_type='ca', x0=None, dt=dt):\n",
    "        \"\"\"Initialize Kalman Filter object for the track\"\"\"\n",
    "        if x0 is None:\n",
    "            x0 = np.array([0, 0.5, 0.2, 0, 0.5, 0.2, 0, 0.5, 0.2]) # dummy object\n",
    "        if model_type == 'ca':\n",
    "            self.filter = KalmanFilter (dim_x=9, dim_z=3)\n",
    "            self.filter.x = np.array([x0.x, 0.5, 0.2, x0.y, 0.5, 0.2, x0.z, 0.5, 0.2])\n",
    "            self.filter.F = linear_transition_matrix(dt)\n",
    "            self.filter.H = H\n",
    "            self.filter.P *= 0.1 \n",
    "            self.filter.Q = np.eye(9) * 0.005 \n",
    "            self.filter.R = np.diag(np.array([0.5, 0.2, 0.05])) * 0.01 \n",
    "            \n",
    "    def update_Kalman_Filter(self, y):\n",
    "        \"\"\"Perform Kalman Filter update with observed data y\"\"\"\n",
    "        y = np.array(y)\n",
    "        self.filter.update(y)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"ID: %d, status: %s, x: %f, y:%f, z:%f, new_time: %f, pending_time: %f, objects_count: %d, frame_count: %d\"%(self.ID, self.status, self.x, self.y, self.z, self.new_time, self.pending_time, len(self.objects), len(self.frames))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"ID %d - TimeNew %d\\n - Last coords (%f,%f,%f)\" %(self.ID, self.new_time, self.x, self.y, self.z)\n",
    "    \n",
    "    \n",
    "    def detection_vs_filter(self):\n",
    "        plt.figure()\n",
    "        plt.title('Detections vs Filter for Track: '+ str(self.ID))\n",
    "        abscissa = [pos[0] for pos in self.all_positions ]\n",
    "        ordinate = [pos[1] for pos in self.all_positions ]\n",
    "        plt.ylim((np.min(ordinate)-5,np.max(ordinate)+5))\n",
    "        plt.xlim((np.min(abscissa)-5,np.max(abscissa)+5))\n",
    "        plt.scatter(abscissa[0], ordinate[0], color = 'r')\n",
    "        plt.plot(abscissa, ordinate, color = 'r', label = 'Filter')\n",
    "        plt.scatter(abscissa[-1], ordinate[-1], color = 'r')\n",
    "        abscissa = [pos.x for pos in self.objects]\n",
    "        ordinate = [pos.y for pos in self.objects]\n",
    "        plt.scatter(abscissa[0], ordinate[0], color = 'b')\n",
    "        plt.plot(abscissa, ordinate, color = 'b', label = 'Detection')\n",
    "        plt.scatter(abscissa[-1], ordinate[-1], color = 'b')\n",
    "        \n",
    "        plt.legend()\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function needed to join cameras\n",
    "\n",
    "def custom_prob(obj1, obj2):\n",
    "    \n",
    "    #Mean is center of obj1, std dimension of the boxes, we mulltiply cov by a coefficient related to distance in time\n",
    "    time_coef = 0.05 #0.05 Ok with 0.06 as timestep, probably better 0.03 with 0.08\n",
    "    mean = obj1[0:3]\n",
    "    std = obj1[3:6]\n",
    "    cov = np.diag(np.power(std,2)) * np.exp(np.abs(obj1[7] - obj2[7])/time_coef, dtype = np.float64)\n",
    "\n",
    "    x = obj2[:3]\n",
    "\n",
    "    m_dist_x = np.dot((x-mean).transpose(),np.linalg.inv(cov))\n",
    "    m_dist_x = np.dot(m_dist_x, (x-mean))\n",
    "    \n",
    "    dist = 1-stats.chi2.cdf(m_dist_x, 3)\n",
    "    \n",
    "    #If objs belong to same camera -> 0 prob of being same one\n",
    "    if dist != 1 and obj1[9] == obj2[9] and obj1[7] == obj2[7]:\n",
    "        return 0\n",
    "    \n",
    "    return dist\n",
    "\n",
    "def unify(frame):\n",
    "    \n",
    "    #Convert Frame to array\n",
    "    frame_values = frame.iloc[:,:].values\n",
    "\n",
    "    #Compute probabilities\n",
    "    dists = cdist(frame_values, frame_values, custom_prob)\n",
    "    \n",
    "    #Create index array\n",
    "    index = np.empty(shape = (len(frame.index)))\n",
    "    index[:] = np.nan\n",
    "    \n",
    "    #Compute first argmax\n",
    "    argmax = np.unravel_index(dists.argmax(), dists.shape)\n",
    "    max_value = np.max(dists) \n",
    "    \n",
    "    #Cycle on maxima\n",
    "    while max_value > 0.35:\n",
    "    \n",
    "        if argmax[0] == argmax[1]:\n",
    "            dists[argmax] = -1\n",
    "\n",
    "        if argmax[0] != argmax[1]:\n",
    "            if dists[argmax[0], argmax[1]] > 0.5 and dists[argmax[1], argmax[0]] > 0.1:\n",
    "                if np.isnan(index[argmax[1]]):\n",
    "                    if np.isnan(index[argmax[0]]):\n",
    "                        index[argmax[0]] = argmax[0]\n",
    "                    index[argmax[1]] = index[argmax[0]]\n",
    "            dists[argmax] = -1\n",
    "    \n",
    "        argmax = np.unravel_index(dists.argmax(), dists.shape)\n",
    "        max_value = dists[argmax]\n",
    "\n",
    "    #Fill index vectors\n",
    "    for i in range(index.shape[0]):\n",
    "        if np.isnan(index[i]):\n",
    "            index[i] = i\n",
    "    \n",
    "    #Add index column\n",
    "    frame['object_index'] = index\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Methods to compute IoU and associate boxes through IoU\n",
    "\n",
    "def belongs_to(point, box, isdf=False):\n",
    "    \"\"\"Utility function that returns true if the point is found within the box, false otherwise\"\"\"\n",
    "    \n",
    "    if isdf:\n",
    "        center = box[['X_box', 'Y_box', 'Z_box']].to_numpy().flatten()\n",
    "        point = np.array([i for i in point]) - center\n",
    "        anti_rotation_matrix = np.array([[np.cos(-box['angle_box'].to_numpy()[0]), -np.sin(-box['angle_box'].to_numpy()[0]), 0], \n",
    "                            [np.sin(-box['angle_box'].to_numpy()[0]), np.cos(-box['angle_box'].to_numpy()[0]), 0], \n",
    "                            [0,0,1]])\n",
    "        rot_point = anti_rotation_matrix.dot(point)\n",
    "        \n",
    "        if np.abs(rot_point[0])<box['length_box'].to_numpy()/2 and np.abs(rot_point[1])<box['width_box'].to_numpy()/2 and np.abs(rot_point[2])<box['height_box'].to_numpy()/2:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    center = np.array([i for i in box[0]])\n",
    "    point = np.array([i for i in point]) - center\n",
    "    anti_rotation_matrix = np.array([[np.cos(-box[4]), -np.sin(-box[4]), 0], \n",
    "                            [np.sin(-box[4]), np.cos(-box[4]), 0], \n",
    "                            [0,0,1]])\n",
    "    rot_point = anti_rotation_matrix.dot(point)\n",
    "    \n",
    "    if np.abs(rot_point[0])<box[1]/2 and np.abs(rot_point[1])<box[2]/2 and np.abs(rot_point[2])<box[3]/2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def compute_approx_IoU(box1, box2, attempts=100): \n",
    "    \"\"\"Compute an approximated IoU between two boxes with a Monte Carlo approach\"\"\"\n",
    "\n",
    "    # store measures in meaningful variables\n",
    "    pos1 = box1[['X_box', 'Y_box', 'Z_box']].to_numpy().flatten()\n",
    "    pos2 = box2[['X_box', 'Y_box', 'Z_box']].to_numpy().flatten()\n",
    "    length1 = box1['length_box'].to_numpy()[0]\n",
    "    width1 = box1['width_box'].to_numpy()[0]\n",
    "    height1 = box1['height_box'].to_numpy()[0]\n",
    "    length2 = box2['length_box'].to_numpy()[0]\n",
    "    width2 = box2['width_box'].to_numpy()[0]\n",
    "    height2 = box2['height_box'].to_numpy()[0]\n",
    "    diag1 = np.sqrt(length1**2+width1**2+height1**2)\n",
    "    diag2 = np.sqrt(length2**2+width2**2+height2**2)\n",
    "    rotation_matrix1 = np.array([[np.cos(box1['angle_box'].to_numpy())[0], -np.sin(box1['angle_box'].to_numpy()[0]), 0], \n",
    "                            [np.sin(box1['angle_box'].to_numpy()[0]), np.cos(box1['angle_box'].to_numpy()[0]), 0], \n",
    "                            [0,0,1]])\n",
    "    rotation_matrix2 = np.array([[np.cos(box2['angle_box'].to_numpy()[0]), -np.sin(box2['angle_box'].to_numpy()[0]), 0], \n",
    "                            [np.sin(box2['angle_box'].to_numpy()[0]), np.cos(box2['angle_box'].to_numpy()[0]), 0], \n",
    "                            [0,0,1]])\n",
    "    \n",
    "    # return 0 if boxes are non-overlapping\n",
    "    if np.sqrt((pos1[0]-pos2[0])**2+(pos1[1]-pos2[1])**2+(pos1[2]-pos2[2])**2)>max(diag1, diag2):\n",
    "        return 0\n",
    "    \n",
    "    # if an overlap exists, estimate IoU by drawing random points in each box and checking how many also belong to the other\n",
    "    intersection = 0\n",
    "    \n",
    "    for i in range(attempts):\n",
    "        u = np.random.uniform(-1,1,size=3) * np.array([length1,width1,height1])/2 \n",
    "        u = rotation_matrix1.dot(u)\n",
    "        if belongs_to(u + np.array([i for i in pos1]), box2, True):\n",
    "            intersection +=1\n",
    "        u = np.random.uniform(-1,1,size=3) * np.array([length2,width2,height2])/2 \n",
    "        u = rotation_matrix2.dot(u)\n",
    "        if belongs_to(u + np.array([i for i in pos2]), box1, True):\n",
    "            intersection +=1\n",
    "    return intersection/2/attempts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions used to associate tracks and detections\n",
    "\n",
    "def find_subsequent_boxes(track_list1, track_list2):\n",
    "    \"\"\"\n",
    "    Returns a numpy array of the best matches of boxes in track_list2 for boxes in track_list1, if any.\n",
    "    If no IoU above a fixed threshold is found, -1 is assigned.\n",
    "    \"\"\"\n",
    "    \n",
    "    iou_vals = np.zeros(shape=(len(track_list1), len(track_list2)))\n",
    "    \n",
    "    for i in range(len(track_list1)):\n",
    "        for j in range(len(track_list2)):\n",
    "\n",
    "            df1 = track_list1[i].to_df()\n",
    "            last_frame = df1.frame.max()\n",
    "            iou = compute_approx_IoU(df1[df1.frame==last_frame],track_list2[j].to_df())\n",
    "            iou_vals[i][j] = iou\n",
    "        \n",
    "    return iou_vals\n",
    "\n",
    "def track_detection_association(track_coord, obj_coord):\n",
    "    ''' Function for computing the euclidean distance between detections and predicted track positions'''\n",
    "    \n",
    "    dists = cdist(track_coord, obj_coord, 'euclidean') \n",
    "\n",
    "    return dists\n",
    "\n",
    "### Perform association of objects in previous and next frame\n",
    "\n",
    "def associate(tracks, obj_list, frame_index):\n",
    "    \n",
    "    all_tracks = tracks.items()\n",
    "    all_tracks = np.array([track for cat, trs in all_tracks if cat in ['Active', 'New', 'Pending'] for track in trs])\n",
    "    track_coord = np.array([[t.x, t.y, t.z] for t in all_tracks]) \n",
    "    track_indices = np.array([t.ID for t in all_tracks])\n",
    "    \n",
    "    if track_coord.size and len(obj_list) > 0:\n",
    "        \n",
    "        # explore with iou\n",
    "        \n",
    "        iou_values = find_subsequent_boxes(all_tracks, obj_list)\n",
    "\n",
    "        obj_coord = [(obj.x, obj.y, obj.z) for obj in obj_list]\n",
    "        dist_values = track_detection_association(track_coord, obj_coord)\n",
    "        \n",
    "        complete_dists = 0.1 * (1-iou_values) + 0.9 * dist_values\n",
    "        \n",
    "        object_associations = complete_dists.argmin(axis=0)\n",
    "        best_dists_obj = complete_dists.min(axis=0)\n",
    "        \n",
    "        best_dist = complete_dists.min()\n",
    "        object_associations[best_dists_obj>best_dist+max_dist_threshold] = -1\n",
    "        \n",
    "        associations = - np.ones(shape=len(all_tracks), dtype=np.int8)\n",
    "        final_distances = - np.ones(shape=len(all_tracks))\n",
    "        \n",
    "        for index in range(len(associations)):\n",
    "            correspondences = np.where(object_associations==index)[0]\n",
    "            best_sub_dists = best_dists_obj[correspondences]\n",
    "\n",
    "            if(len(correspondences)>0):\n",
    "                idx = np.argmin(best_sub_dists)\n",
    "                associations[index] = correspondences[idx]\n",
    "                final_distances[index] = best_sub_dists[idx]\n",
    "            \n",
    "        \n",
    "        #print(\"Track IDs and corresponding distances: \")\n",
    "        #print(track_indices)\n",
    "        #print(final_distances)\n",
    "        \n",
    "        for index, ass in enumerate(associations):\n",
    "            if ass == -1:\n",
    "                all_tracks[index].update(None, frame_index)\n",
    "            else:\n",
    "                all_tracks[index].update(obj_list[ass], frame_index)\n",
    "\n",
    "        obj_list = np.delete(obj_list, associations)\n",
    "    \n",
    "\n",
    "    return obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class tracker\n",
    "\n",
    "class Tracker:\n",
    "    \n",
    "    def __init__(self, dfs):\n",
    "        self.tracks = {'Active': [], 'Pending': [], 'Inactive': [], 'New': [], 'Removed': []}\n",
    "        self.dataframe = concatenate_dfs(dfs, ['frame', 'camera'])\n",
    "        self.track_id = 0 \n",
    "        self.time = -0.06\n",
    "        self.current_objects = pd.DataFrame()\n",
    "        self.frame_index = -1\n",
    "        \n",
    "    \n",
    "    def update_tracks(self):\n",
    "        ''' Update the status of the tracks, moving them to the different lists'''\n",
    "        for tr in self.tracks['New'][::-1]:\n",
    "            if tr.status != 'New':\n",
    "                self.tracks['New'].remove(tr)\n",
    "                self.tracks[tr.status].append(tr)\n",
    "        \n",
    "        for tr in self.tracks['Pending'][::-1]:\n",
    "            if tr.status != 'Pending':\n",
    "                self.tracks['Pending'].remove(tr)\n",
    "                self.tracks[tr.status].append(tr)\n",
    "        \n",
    "        for tr in self.tracks['Active'][::-1]:\n",
    "            if tr.status != 'Active':\n",
    "                self.tracks['Active'].remove(tr)\n",
    "                self.tracks[tr.status].append(tr)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def next_step(self):\n",
    "        '''Proceed with next time step analysis of frames'''\n",
    "        self.frame_index += 1\n",
    "        self.time += dt\n",
    "        self.current_objects = self.dataframe[np.abs(self.dataframe['elapsed_time']-self.time)<=dt/2]# very unlikely one happens to be EXACTLY in the middle\n",
    "        self.merge_collisions()\n",
    "        self.analyze_frame()\n",
    "        \n",
    "    \n",
    "    def analyze_frame(self):\n",
    "        ''' Analyze frame creating or updating trajectories'''\n",
    "        \n",
    "        frame = self.current_objects \n",
    "        obj_list = []\n",
    "        \n",
    "        # Extract all the detections in the frame\n",
    "        for index, row in frame.iterrows():\n",
    "            obj = Object(row['X_box'], row['Y_box'], row['Z_box'], row['length_box'], \n",
    "                         row['width_box'], row['height_box'], row['angle_box'], row['camera'])\n",
    "            obj_list.append(obj)\n",
    "\n",
    "        obj_list = np.array(obj_list)\n",
    "        \n",
    "        # Perform associations\n",
    "        obj_list = associate( self.tracks, obj_list, self.frame_index)\n",
    "        \n",
    "        # Check status of all tracks\n",
    "        self.update_tracks()        \n",
    "        \n",
    "        #Create new tracks for not linked objects\n",
    "        for obj in obj_list:\n",
    "            tr = Track(self.track_id, obj, self.frame_index)\n",
    "            self.track_id += 1\n",
    "            self.tracks['New'].append(tr)\n",
    "        \n",
    "        \n",
    "    def merge_collisions(self):\n",
    "        \n",
    "        if 'credibility_level' not in self.current_objects:\n",
    "            credibility_level(self.current_objects)\n",
    "        \n",
    "        unify(self.current_objects)\n",
    "        labeled_df = self.current_objects\n",
    "        \n",
    "        if np.all(labeled_df.groupby(['object_index']).count()==1):\n",
    "            return \n",
    "        \n",
    "        labeled_df.loc[:,~labeled_df.columns.isin(['credibility_level', 'camera', 'object_index'])] = labeled_df.loc[:,~labeled_df.columns.isin(['credibility_level', 'camera', 'object_index'])].multiply(labeled_df.credibility_level, axis='index')\n",
    "        \n",
    "        \n",
    "        labeled_df = labeled_df.groupby(['object_index']).sum()\n",
    "        labeled_df = labeled_df.divide(labeled_df.credibility_level, axis='index')\n",
    "        labeled_df = labeled_df.drop(['credibility_level', 'frame'], axis=1)\n",
    "        \n",
    "        self.current_objects = labeled_df\n",
    "        self.current_objects['elapsed_time'] = self.time\n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "    def iterate_for(self,n_iter):\n",
    "        for i in range(n_iter):\n",
    "            self.next_step()\n",
    "            self.summary_track_types(i)\n",
    "        \n",
    "        cmap = plt.get_cmap('tab20')\n",
    "        num = len(cmap.colors)\n",
    "        colors = [cmap(i) for i in np.linspace(0,1,num)]\n",
    "        self.print_tracks(colors, num)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def print_tracks(self,colors,num_cols):\n",
    "        plt.figure()\n",
    "        plt.title(\"plot of Active and New tracks\")\n",
    "        for t in self.tracks['Active']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], color = colors[t.ID%num_cols])\n",
    "            # plt.annotate(t.ID, (abscissa[0],ordinate[0]))\n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], color = colors[t.ID%num_cols])\n",
    "            \n",
    "        for t in self.tracks['New']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], color = colors[t.ID%num_cols])\n",
    "            # plt.annotate(t.ID, (abscissa[0],ordinate[0]))\n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], color = colors[t.ID%num_cols])\n",
    "        plt.figure()\n",
    "        plt.title(\"plot of Pending and Inactive tracks\")\n",
    "        for t in self.tracks['Inactive']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], marker = \"*\", color = colors[t.ID%num_cols])\n",
    "            # plt.annotate(t.ID, (abscissa[0],ordinate[0]))\n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], marker = \"*\", color = colors[t.ID%num_cols])\n",
    "            \n",
    "        for t in self.tracks['Pending']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], color = colors[t.ID%num_cols])\n",
    "            # plt.annotate(t.ID, (abscissa[0],ordinate[0]))\n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], color = colors[t.ID%num_cols])\n",
    "        \n",
    "        return\n",
    "        \n",
    "    \n",
    "    def summary_track_types(self, n ):\n",
    "        print(\"-------------------------------- Iteration N \", n+1, \"--------------------------------\")\n",
    "        print(\"Active tracks: \", len(self.tracks['Active']), 5*\" \", \"New tracks: \", len(self.tracks['New']),\n",
    "              5*\" \", \"Pending tracks: \", len(self.tracks['Pending']), 5*\" \", \"Removed tracks: \", \n",
    "              len(self.tracks['Removed']) ,5*\" \", \"Inactive tracks: \", len(self.tracks['Inactive']) )\n",
    "        print(\"\\n\")\n",
    "    \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo and performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------- Iteration N  1 --------------------------------\n",
      "Active tracks:  0       New tracks:  8       Pending tracks:  0       Removed tracks:  0       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  2 --------------------------------\n",
      "Active tracks:  0       New tracks:  10       Pending tracks:  0       Removed tracks:  0       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  3 --------------------------------\n",
      "Active tracks:  0       New tracks:  10       Pending tracks:  0       Removed tracks:  0       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  4 --------------------------------\n",
      "Active tracks:  0       New tracks:  12       Pending tracks:  0       Removed tracks:  0       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  5 --------------------------------\n",
      "Active tracks:  0       New tracks:  14       Pending tracks:  0       Removed tracks:  1       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  6 --------------------------------\n",
      "Active tracks:  0       New tracks:  12       Pending tracks:  0       Removed tracks:  3       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  7 --------------------------------\n",
      "Active tracks:  0       New tracks:  13       Pending tracks:  0       Removed tracks:  3       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  8 --------------------------------\n",
      "Active tracks:  7       New tracks:  8       Pending tracks:  0       Removed tracks:  3       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  9 --------------------------------\n",
      "Active tracks:  7       New tracks:  7       Pending tracks:  0       Removed tracks:  4       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  10 --------------------------------\n",
      "Active tracks:  7       New tracks:  7       Pending tracks:  0       Removed tracks:  4       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  11 --------------------------------\n",
      "Active tracks:  7       New tracks:  9       Pending tracks:  1       Removed tracks:  4       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  12 --------------------------------\n",
      "Active tracks:  8       New tracks:  8       Pending tracks:  1       Removed tracks:  4       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  13 --------------------------------\n",
      "Active tracks:  8       New tracks:  9       Pending tracks:  1       Removed tracks:  4       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  14 --------------------------------\n",
      "Active tracks:  9       New tracks:  7       Pending tracks:  1       Removed tracks:  5       Inactive tracks:  0\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  15 --------------------------------\n",
      "Active tracks:  10       New tracks:  7       Pending tracks:  0       Removed tracks:  5       Inactive tracks:  1\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  16 --------------------------------\n",
      "Active tracks:  9       New tracks:  7       Pending tracks:  1       Removed tracks:  5       Inactive tracks:  1\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  17 --------------------------------\n",
      "Active tracks:  8       New tracks:  7       Pending tracks:  2       Removed tracks:  5       Inactive tracks:  1\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  18 --------------------------------\n",
      "Active tracks:  8       New tracks:  8       Pending tracks:  2       Removed tracks:  5       Inactive tracks:  1\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  19 --------------------------------\n",
      "Active tracks:  9       New tracks:  7       Pending tracks:  1       Removed tracks:  6       Inactive tracks:  1\n",
      "\n",
      "\n",
      "-------------------------------- Iteration N  20 --------------------------------\n",
      "Active tracks:  8       New tracks:  7       Pending tracks:  1       Removed tracks:  6       Inactive tracks:  2\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Tracker, analyze some frames\n",
    "TrackTrack = Tracker([df_109,df_130,df_142,df_143])\n",
    "TrackTrack.iterate_for(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_box</th>\n",
       "      <th>Y_box</th>\n",
       "      <th>Z_box</th>\n",
       "      <th>length_box</th>\n",
       "      <th>width_box</th>\n",
       "      <th>height_box</th>\n",
       "      <th>angle_box</th>\n",
       "      <th>camera</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.560173</td>\n",
       "      <td>18.983654</td>\n",
       "      <td>-1.377405</td>\n",
       "      <td>3.325998</td>\n",
       "      <td>0.953963</td>\n",
       "      <td>1.498572</td>\n",
       "      <td>-0.120755</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.487168</td>\n",
       "      <td>19.018149</td>\n",
       "      <td>-1.403667</td>\n",
       "      <td>2.751621</td>\n",
       "      <td>1.204600</td>\n",
       "      <td>1.533254</td>\n",
       "      <td>-0.508305</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.471875</td>\n",
       "      <td>18.917938</td>\n",
       "      <td>-1.344490</td>\n",
       "      <td>2.740135</td>\n",
       "      <td>1.523416</td>\n",
       "      <td>1.553007</td>\n",
       "      <td>-0.697685</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.183624</td>\n",
       "      <td>18.597415</td>\n",
       "      <td>-1.355930</td>\n",
       "      <td>1.283514</td>\n",
       "      <td>0.745171</td>\n",
       "      <td>1.878356</td>\n",
       "      <td>0.409065</td>\n",
       "      <td>109.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.246327</td>\n",
       "      <td>18.480157</td>\n",
       "      <td>-1.370194</td>\n",
       "      <td>1.436779</td>\n",
       "      <td>0.704693</td>\n",
       "      <td>1.725794</td>\n",
       "      <td>0.366784</td>\n",
       "      <td>109.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-9.251641</td>\n",
       "      <td>18.383025</td>\n",
       "      <td>-1.365100</td>\n",
       "      <td>1.253955</td>\n",
       "      <td>0.661718</td>\n",
       "      <td>1.629647</td>\n",
       "      <td>0.235827</td>\n",
       "      <td>109.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-9.383795</td>\n",
       "      <td>18.202067</td>\n",
       "      <td>-1.365403</td>\n",
       "      <td>1.234077</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.686681</td>\n",
       "      <td>0.225427</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9.299302</td>\n",
       "      <td>18.152167</td>\n",
       "      <td>-1.361036</td>\n",
       "      <td>1.230536</td>\n",
       "      <td>0.588501</td>\n",
       "      <td>1.851735</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-9.447539</td>\n",
       "      <td>18.002991</td>\n",
       "      <td>-1.356579</td>\n",
       "      <td>1.319826</td>\n",
       "      <td>0.654763</td>\n",
       "      <td>1.966696</td>\n",
       "      <td>0.403460</td>\n",
       "      <td>109.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-9.443646</td>\n",
       "      <td>17.910826</td>\n",
       "      <td>-1.466725</td>\n",
       "      <td>1.231907</td>\n",
       "      <td>0.696082</td>\n",
       "      <td>1.644936</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_box      Y_box     Z_box  length_box  width_box  height_box  \\\n",
       "0 -9.560173  18.983654 -1.377405    3.325998   0.953963    1.498572   \n",
       "1 -9.487168  19.018149 -1.403667    2.751621   1.204600    1.533254   \n",
       "2 -9.471875  18.917938 -1.344490    2.740135   1.523416    1.553007   \n",
       "3 -9.183624  18.597415 -1.355930    1.283514   0.745171    1.878356   \n",
       "4 -9.246327  18.480157 -1.370194    1.436779   0.704693    1.725794   \n",
       "5 -9.251641  18.383025 -1.365100    1.253955   0.661718    1.629647   \n",
       "6 -9.383795  18.202067 -1.365403    1.234077   0.617000    1.686681   \n",
       "7 -9.299302  18.152167 -1.361036    1.230536   0.588501    1.851735   \n",
       "8 -9.447539  18.002991 -1.356579    1.319826   0.654763    1.966696   \n",
       "9 -9.443646  17.910826 -1.466725    1.231907   0.696082    1.644936   \n",
       "\n",
       "   angle_box  camera  frame  \n",
       "0  -0.120755   109.0    0.0  \n",
       "1  -0.508305   109.0    1.0  \n",
       "2  -0.697685   109.0    2.0  \n",
       "3   0.409065   109.0    3.0  \n",
       "4   0.366784   109.0    4.0  \n",
       "5   0.235827   109.0    5.0  \n",
       "6   0.225427   109.0    6.0  \n",
       "7   0.202899   109.0    7.0  \n",
       "8   0.403460   109.0    8.0  \n",
       "9   0.357000   109.0    9.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print one trajectory as dataframe\n",
    "TrackTrack.tracks['Active'][5].to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['Active'][6].detection_vs_filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps and what could be improved \n",
    ".... (be straightforward but also underline the value in your work so far)\n",
    "\n",
    "To me a next step is to tune thresholds and evaluate the model\n",
    "A possible improvement is the flow of information rather than condensation of information all in one - we can provide a skeleton for it\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
