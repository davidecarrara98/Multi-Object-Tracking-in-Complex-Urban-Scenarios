{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi object tracking in complex urban scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed \n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '../Data/data_109.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19196/888903984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# upload data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhdf5data_109\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/data_109.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhdf5data_130\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/data_130.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhdf5data_142\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/data_142.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhdf5data_143\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/data_143.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Viscando\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Viscando\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '../Data/data_109.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# upload data \n",
    "hdf5data_109 = h5py.File('../../Data/data_109.h5', 'r')\n",
    "hdf5data_130 = h5py.File('../../Data/data_130.h5', 'r')\n",
    "hdf5data_142 = h5py.File('../../Data/data_142.h5', 'r')\n",
    "hdf5data_143 = h5py.File('../../Data/data_143.h5', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer data into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_rows_detections(detections, returndf):\n",
    "    \n",
    "    coord_detections = [np.array(vals[0].tolist()) for vals in detections]\n",
    "    coord_detections = np.vstack(coord_detections)\n",
    "        \n",
    "    length_box = [vals[1] for vals in detections]\n",
    "    width_box = [vals[2] for vals in detections]\n",
    "    height_box = [vals[3] for vals in detections]\n",
    "    angle_box = [vals[4] for vals in detections]\n",
    "    \n",
    "    returndf[\"X_box\"] = coord_detections[:,0]\n",
    "    returndf[\"Y_box\"] = coord_detections[:,1]\n",
    "    returndf[\"Z_box\"] = coord_detections[:,2]\n",
    "    returndf[\"length_box\"], returndf[\"width_box\"], returndf[\"height_box\"] = length_box, width_box, height_box\n",
    "    returndf[\"angle_box\"] = angle_box\n",
    "    \n",
    "    return returndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_detections(h5data,camera = None):\n",
    "    \n",
    "    timestamps = h5data['Timestamp']\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for c, t in enumerate(timestamps):\n",
    "        \n",
    "        append_df = pd.DataFrame()\n",
    "        \n",
    "        d = h5data['Sequence'][str(c)]\n",
    "        detection = np.asarray(d['Detections'])\n",
    "        \n",
    "        if detection.size:\n",
    "            append_df = fill_rows_detections(detection, append_df)\n",
    "            append_df['timestamp'] = t\n",
    "            append_df['frame'] = c\n",
    "        \n",
    "            if camera is not None:\n",
    "                append_df['camera'] = camera\n",
    "        \n",
    "            df = df.append(append_df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_109 = df_detections(hdf5data_109, 109)\n",
    "df_109.reset_index(inplace=True, drop=True)\n",
    "df_130 = df_detections(hdf5data_130, 130)\n",
    "df_130.reset_index(inplace=True, drop=True)\n",
    "df_142 = df_detections(hdf5data_142, 142)\n",
    "df_142.reset_index(inplace=True, drop=True)\n",
    "df_143 = df_detections(hdf5data_143, 143)\n",
    "df_143.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_dfs(dfs, sort_cols):\n",
    "    \n",
    "    df_to_concat = dfs\n",
    "    df_complete = pd.concat(df_to_concat)\n",
    "    df_complete.sort_values(by = sort_cols, inplace = True)\n",
    "    df_complete.reset_index(inplace=True, drop=True)\n",
    "    df_complete['elapsed_time'] = df_complete['timestamp']-df_complete['timestamp'].min()\n",
    "    \n",
    "    return df_complete\n",
    "\n",
    "df_complete = concatenate_dfs([df_109,df_130,df_142,df_143] , ['frame', 'camera'])\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add reliability of measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define coordinate transformation useful to find credibility levels\n",
    "def convert_to_image_space ( coordinates , world2cam , cam2im ):\n",
    "    \"\"\" Input single set of coordinatetes \"\"\"\n",
    "    coord_4 = np.ones (4)\n",
    "    coord_4[0:3] = coordinates\n",
    "    cams_coord = ( np.matmul( world2cam , coord_4.T )).T\n",
    "    cams_coord_4 = np.ones(4)\n",
    "    \n",
    "    cams_coord_4 [0:3] = cams_coord [0:3]\n",
    "    ims_coord = ( np . matmul ( cam2im , cams_coord_4 .T )). T\n",
    "    # Divide by z coordinate for some reason\n",
    "    ims_coord [0] = ims_coord [0]/ ims_coord [2]\n",
    "    ims_coord [1] = ims_coord [1]/ ims_coord [2]\n",
    "    ims_coord = ims_coord [0:2]\n",
    "    \n",
    "    return ( ims_coord )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credibility_level(df):\n",
    "    df['credibility_level'] = np.zeros(shape = len(df.index))\n",
    "    for ind,row in df.iterrows():\n",
    "        coordinates = row[['X_box','Y_box','Z_box']]\n",
    "        \n",
    "        if row['camera'] == 109: \n",
    "            df.at[ind,'credibility_level'] = level_affidability_109(coordinates);\n",
    "            \n",
    "                    \n",
    "        elif row['camera'] == 130:\n",
    "            df.at[ind,'credibility_level'] = level_affidability_130(coordinates);\n",
    "            \n",
    "            \n",
    "        elif row['camera'] == 142:\n",
    "            df.at[ind,'credibility_level'] = level_affidability_142(coordinates);\n",
    "         \n",
    "        \n",
    "        if row['camera'] == 143:\n",
    "            df.at[ind,'credibility_level'] = level_affidability_143(coordinates);\n",
    "        \n",
    "\n",
    "                \n",
    "def level_affidability_109(coordinates):\n",
    "    world2cam = hdf5data_109['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_109['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    sloap1 = (-250 + 121.374145)/(600-296.40511363)\n",
    "    sloap2 = 8/65\n",
    "    if - img_coord[1] <= sloap1*(img_coord[0] - 600) - 250:\n",
    "        return 1\n",
    "    elif - img_coord[1] <= sloap2*(img_coord[0]) - 180:\n",
    "        return 0.75\n",
    "    else:\n",
    "        return 0.25\n",
    "\n",
    "    \n",
    "def level_affidability_130(coordinates):\n",
    "    world2cam = hdf5data_130['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_130['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    if (img_coord[0] <= 630) & (img_coord[1] >= 100):\n",
    "        return 1\n",
    "    elif (img_coord[0] <= 560) & (img_coord[0] >= 420):\n",
    "        return 0.25\n",
    "    else: \n",
    "        return 0.5\n",
    "    \n",
    "\n",
    "    \n",
    "def level_affidability_142(coordinates):\n",
    "    world2cam = hdf5data_142['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_142['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    if (img_coord[0] >= 535) & (img_coord[0] <= 575) & (img_coord[1] <= 160) & (img_coord[1] >= 50):\n",
    "        return 0.25\n",
    "    if (img_coord[0] <= 570) & (img_coord[0] >= 380) & (img_coord[1] <= 70):\n",
    "        return 0.25\n",
    "    elif img_coord[1] > 70:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0.75\n",
    "\n",
    "    \n",
    "def level_affidability_143(coordinates):\n",
    "    world2cam = hdf5data_143['TMatrixWorldToCam']\n",
    "    cam2im = hdf5data_143['ProjectionMatrix']\n",
    "    img_coord = convert_to_image_space ( coordinates , world2cam , cam2im )\n",
    "    if (img_coord[0] >= 420) & (img_coord[1] <= 120):\n",
    "        return 0.25\n",
    "    if (img_coord[0] < 410) & (img_coord[1] <= 120):\n",
    "        return 0.5\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credibility_level(df_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_frame_detections ( camera, frame_idx, figsize = None , s = 100):\n",
    "    \"\"\" Input camera file, frame index and size of dot in the picture (default is 100) \"\"\"\n",
    "    \n",
    "    frame = camera['Sequence'][str(frame_idx)]\n",
    "    detected_points = np.asarray(frame['Detections'])\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for point in detected_points:\n",
    "    \n",
    "        world_pos = np.array(point[0].tolist())\n",
    "        fin_pos = convert_to_image_space(world_pos, camera['TMatrixWorldToCam'], camera['ProjectionMatrix'])\n",
    "        x_list.append(fin_pos[0])\n",
    "        y_list.append(fin_pos[1])\n",
    "    \n",
    "    \n",
    "\n",
    "    # Show image\n",
    "    a = np.asarray(frame['Image'])\n",
    "    \n",
    "    if figsize is not None: \n",
    "        plt.figure(figsize = figsize)\n",
    "        \n",
    "    plt.imshow(a, cmap = 'gist_gray', zorder = 1)\n",
    "    plt.scatter(x_list, y_list, s = s, color = 'hotpink', zorder = 3)\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def visualize_frame_boxes ( camera, frame_idx, figsize = None, s = 100):\n",
    "    \"\"\" Input camera file, frame index and size of dot in the picture (default is 100) \"\"\"\n",
    "    \n",
    "    frame = camera['Sequence'][str(frame_idx)]\n",
    "    detected_points = np.asarray(frame['Detections'])\n",
    "    \n",
    "    if figsize is not None: \n",
    "        plt.figure(figsize = figsize)\n",
    "        \n",
    "    \n",
    "    for point in detected_points:\n",
    "        # first face \n",
    "        unrotated_vertex1 = np.array([+ point['Length']/2, + point['Width']/2, + point['Height']/2])\n",
    "        unrotated_vertex2 = np.array([+ point['Length']/2, + point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex3 = np.array([+ point['Length']/2, - point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex4 = np.array([+ point['Length']/2, - point['Width']/2, + point['Height']/2])\n",
    "        # second face \n",
    "        unrotated_vertex5 = np.array([- point['Length']/2, + point['Width']/2, + point['Height']/2])\n",
    "        unrotated_vertex6 = np.array([- point['Length']/2, + point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex7 = np.array([- point['Length']/2, - point['Width']/2, - point['Height']/2])\n",
    "        unrotated_vertex8 = np.array([- point['Length']/2, - point['Width']/2, + point['Height']/2])\n",
    "        \n",
    "        \n",
    "        unrotated_vertex_list = [unrotated_vertex1, unrotated_vertex2, unrotated_vertex3, \n",
    "                                 unrotated_vertex4, unrotated_vertex5, unrotated_vertex6, \n",
    "                                 unrotated_vertex7, unrotated_vertex8]\n",
    "        \n",
    "        rotation_matrix = np.array([[np.cos(point['Angle']), -np.sin(point['Angle']), 0], \n",
    "                            [np.sin(point['Angle']), np.cos(point['Angle']), 0], \n",
    "                            [0,0,1]])\n",
    "        \n",
    "        rotated_vertex_list = np.array([rotation_matrix.dot(v) for v in unrotated_vertex_list])\n",
    "        rotated_vertex_list = rotated_vertex_list + np.array([point['Pos']['X'], point['Pos']['Y'], point['Pos']['Z']])\n",
    "        \n",
    "        vertex_im_list = [convert_to_image_space(v, camera['TMatrixWorldToCam'], camera['ProjectionMatrix']) for v in rotated_vertex_list]\n",
    "        \n",
    "        \n",
    "        combinations = [(i,i+1) for i in range(3)] + [(3,0)] + [(i,i+1) for i in range(4,7)] + [\n",
    "            (7,4)] + [(i,i+4) for i in range(4)]\n",
    "        \n",
    "        for (i,j) in combinations: \n",
    "            vertex_x_list = [vertex_im_list[i][0],vertex_im_list[j][0]]\n",
    "            vertex_y_list = [vertex_im_list[i][1],vertex_im_list[j][1]]\n",
    "            plt.plot(vertex_x_list, vertex_y_list, color = 'b', zorder = 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    visualize_frame_detections ( camera, frame_idx, s = s )\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def visualize_alldetections(df, frame_idx = None):\n",
    "    ''' Visualize all detections from above'''\n",
    "    if frame_idx is not None:\n",
    "        x = df['X_box'][df['frame'] == frame_idx]\n",
    "        y = df['Y_box'][df['frame'] == frame_idx]\n",
    "        display(df[df['frame'] == frame_idx])\n",
    "    \n",
    "    else:\n",
    "        x = df['X_box']\n",
    "        y = df['Y_box']\n",
    "        \n",
    "    plt.scatter(x,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_frame_detections(hdf5data_143,313, figsize = (12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_frame_boxes(hdf5data_109, 260, figsize = (12,12), s = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_alldetections(df_complete, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define some useful constants\n",
    "\n",
    "dt = 0.08\n",
    "new_time_threshold = 7\n",
    "active_time_threshold = 5\n",
    "speed_acc_window = 5\n",
    "H = np.array([[1.,0.,0., 0., 0., 0., 0., 0., 0.],[0.,0., 0.,1., 0., 0., 0., 0., 0.],[0.,0., 0., 0., 0., 0.,1., 0., 0.]])\n",
    "max_dist_threshold = 5\n",
    "\n",
    "\n",
    "def linear_transition_matrix(dt):\n",
    "    \"\"\"Returns matrix F of the Constant Acceleration model\"\"\"\n",
    "    return np.array([[1., dt, 0.5*dt**2, 0., 0., 0., 0., 0., 0.], [0, 1, dt, 0., 0., 0., 0., 0., 0. ], [0.,0.,1., 0., 0., 0., 0., 0., 0.],\n",
    "               [0.,0.,0.,1.,dt,0.5*dt**2,0.,0.,0.],[0.,0.,0.,0.,1.,dt,0.,0.,0.],[0.,0.,0.,0.,0.,1.,0.,0.,0.],\n",
    "               [0.,0.,0.,0.,0.,0.,1.,0.,0.],[0.,0.,0.,0.,0.,0.,0.,0.,0.], [0.,0.,0.,0.,0.,0.,0.,0.,0.]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class representing a single detection\n",
    "\n",
    "class Object:\n",
    "    def __init__(self, x, y, z, l, w, h, angle, camera):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.length = l\n",
    "        self.width = w\n",
    "        self.height = h\n",
    "        self.angle = angle\n",
    "        self.camera = camera\n",
    "        \n",
    "    def to_df(self):\n",
    "        \n",
    "        df = pd.DataFrame([[self.x, self.y, self.z, self.length, self.width, self.height, self.angle, self.camera]], \n",
    "                         columns = ['X_box', 'Y_box', 'Z_box', 'length_box', 'width_box', 'height_box', 'angle_box', 'camera'])\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"x: %f, y:%f, z:%f, length:%f, width:%f, height:%f, angle:%f, camera:%d \\n\" %(self.x, self.y, self.z, self.length, self.width, self.height, self.angle, self.camera)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"x: %f, y:%f, z:%f \\n\" %(self.x, self.y, self.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Class representing the Tracks\n",
    "\n",
    "class Track:\n",
    "    \n",
    "    def __init__(self, ID, OBJ, FRAME, threshold = new_time_threshold):\n",
    "        self.ID = ID\n",
    "        self.status = 'New' \n",
    "        self.objects = [OBJ]\n",
    "        self.x, self.y, self.z = OBJ.x, OBJ.y, OBJ.z\n",
    "        self.frames = [FRAME]\n",
    "        self.velocity = [0.5, 0.5, 0.]\n",
    "        self.acceleration = [0.2, 0.2, 0.]\n",
    "        self.type = None\n",
    "        self.threshold = threshold\n",
    "        self.filter = None\n",
    "        self.new_time = 1\n",
    "        self.pending_time = 0\n",
    "        self.active_time = 0\n",
    "        self.all_positions = [[OBJ.x, OBJ.y, OBJ.z]]\n",
    "        self.all_velocities = [[], [], []]\n",
    "        self.all_accelerations = [[], [], []]\n",
    "        self.pending_status = []\n",
    "        \n",
    "        \n",
    "        self.set_Kalman_Filter(x0 = OBJ)\n",
    "    \n",
    "    def update(self, OBJ, FRAME):\n",
    "        \"\"\"Performs different update routines based on the presence of an associated object or not, and the current status of the track\"\"\"\n",
    "        # predict next state through KF\n",
    "        self.filter.predict()\n",
    "        \n",
    "        # update with object\n",
    "        if OBJ is not None:\n",
    "            self.objects.append(OBJ)\n",
    "            self.frames.append(FRAME)\n",
    "            # update of a new trajectory - velocity and acceleration are estimated through sample averages of observed positions for improving the start conditions\n",
    "            if self.status == 'New':\n",
    "                self.x, self.y, self.z = OBJ.x, OBJ.y, OBJ.z\n",
    "                last_xs = np.array([obj.x for obj in self.objects])\n",
    "                last_ys = np.array([obj.y for obj in self.objects])\n",
    "                last_zs = np.array([obj.z for obj in self.objects])\n",
    "                if len(last_xs)>1:\n",
    "                    self.velocity[0] = np.mean((last_xs[1:]-last_xs[:-1])/dt)\n",
    "                    self.velocity[1] = np.mean((last_ys[1:]-last_ys[:-1])/dt)\n",
    "                    self.velocity[2] = np.mean((last_zs[1:]-last_zs[:-1])/dt)\n",
    "                    \n",
    "                if len(last_xs)>2:\n",
    "                    self.acceleration[0] = (last_xs[2:] - 2* last_xs[1:-1] + last_xs[:-2])[0]/(dt**2)\n",
    "                    self.acceleration[1] = (last_ys[2:] - 2* last_ys[1:-1] + last_ys[:-2])[0]/(dt**2)\n",
    "                    self.acceleration[2] = (last_zs[2:] - 2* last_zs[1:-1] + last_zs[:-2])[0]/(dt**2)\n",
    "                \n",
    "                self.filter.x = np.array([self.x,self.velocity[0], self.acceleration[0],\n",
    "                                          self.y,self.velocity[1], self.acceleration[1],\n",
    "                                          self.z,self.velocity[2], self.acceleration[2]])\n",
    "                self.new_time += 1\n",
    "                if self.new_time > self.threshold:\n",
    "                    self.status = 'Active'\n",
    "                    self.active_time = 1\n",
    "            else:\n",
    "                \n",
    "                # Kalman Filter is updated with observed values\n",
    "                self.update_Kalman_Filter(np.array([OBJ.x, OBJ.y, OBJ.z]))\n",
    "\n",
    "                # for some active time keep using the sample average estimated velocity and acceleration to ensure KF has enough time to converge\n",
    "                if self.active_time < active_time_threshold: \n",
    "                    self.x, self.y, self.z = OBJ.x, OBJ.y, OBJ.z\n",
    "                    last_xs = np.array([obj.x for obj in self.objects[-speed_acc_window:]])\n",
    "                    last_ys = np.array([obj.y for obj in self.objects[-speed_acc_window:]])\n",
    "                    last_zs = np.array([obj.z for obj in self.objects[-speed_acc_window:]])\n",
    "                    \n",
    "                    self.velocity[0] = np.mean((last_xs[1:]-last_xs[:-1])/dt)\n",
    "                    self.velocity[1] = np.mean((last_ys[1:]-last_ys[:-1])/dt)\n",
    "                    self.velocity[2] = np.mean((last_zs[1:]-last_zs[:-1])/dt)\n",
    "                    \n",
    "                    self.acceleration[0] = (last_xs[2:] - 2* last_xs[1:-1] + last_xs[:-2])[0]/(dt**2)\n",
    "                    self.acceleration[1] = (last_ys[2:] - 2* last_ys[1:-1] + last_ys[:-2])[0]/(dt**2)\n",
    "                    self.acceleration[2] = (last_zs[2:] - 2* last_zs[1:-1] + last_zs[:-2])[0]/(dt**2)\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    self.x = self.filter.x[0]\n",
    "                    self.y = self.filter.x[3]\n",
    "                    self.z = self.filter.x[6]\n",
    "                    self.velocity = [self.filter.x[1], self.filter.x[4], self.filter.x[7]]\n",
    "                    self.acceleration = [self.filter.x[2], self.filter.x[5], self.filter.x[8]]\n",
    "                \n",
    "                \n",
    "                self.status = 'Active'\n",
    "                self.active_time += 1\n",
    "            self.all_positions.append([self.x,self.y,self.z])\n",
    "            self.all_velocities[0].append(self.velocity[0])\n",
    "            self.all_velocities[1].append(self.velocity[1])\n",
    "            self.all_velocities[2].append(self.velocity[2])\n",
    "            self.all_accelerations[0].append(self.acceleration[0]) \n",
    "            self.all_accelerations[1].append(self.acceleration[1])\n",
    "            self.all_accelerations[2].append(self.acceleration[2])\n",
    "            self.pending_status.append(0)\n",
    "        \n",
    "        # if no object is available, treat cases by either eliminating the trajectory or setting it as 'Pending'\n",
    "        if OBJ is None and self.status == 'New':\n",
    "            if self.new_time <= 3: \n",
    "                self.status = 'Removed'\n",
    "            else: \n",
    "                self.status = 'Pending'\n",
    "                self.pending_time = 0\n",
    "                \n",
    "        \n",
    "        if OBJ is None and self.status == 'Active':\n",
    "            self.status = 'Pending'\n",
    "            self.pending_time = 0\n",
    "        \n",
    "        if OBJ is None and self.status == 'Pending':                \n",
    "            self.pending_time += 1\n",
    "            if self.pending_time == 5:\n",
    "                self.status = 'Inactive'\n",
    "                self.all_positions = self.all_positions[:-5]\n",
    "            else: \n",
    "                self.x = self.filter.x[0]\n",
    "                self.y = self.filter.x[3]\n",
    "                self.z = self.filter.x[6]\n",
    "                self.velocity = [self.filter.x[1], self.filter.x[4], self.filter.x[7]]\n",
    "                self.acceleration = [self.filter.x[2], self.filter.x[5], self.filter.x[8]]\n",
    "                self.all_positions.append([self.x,self.y,self.z])\n",
    "                self.all_velocities[0].append(self.velocity[0])\n",
    "                self.all_velocities[1].append(self.velocity[1])\n",
    "                self.all_velocities[2].append(self.velocity[2])\n",
    "                self.all_accelerations[0].append(self.acceleration[0]) \n",
    "                self.all_accelerations[1].append(self.acceleration[1])\n",
    "                self.all_accelerations[2].append(self.acceleration[2])\n",
    "                self.pending_status.append(1)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def set_status(self, status):\n",
    "        self.status = status\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def to_df(self):\n",
    "        '''Print Trajectory as Dataframe'''\n",
    "        df = pd.DataFrame(columns = ['X_box', 'Y_box', 'Z_box', 'length_box', 'width_box', 'height_box', 'angle_box', 'camera'])\n",
    "        for i, j in enumerate(self.objects):\n",
    "            append_df = j.to_df()\n",
    "            append_df['frame'] = self.frames[i]       \n",
    "            df = df.append(append_df)\n",
    "            df.reset_index(inplace=True, drop=True)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def set_Kalman_Filter(self, model_type='ca', x0=None, dt=dt):\n",
    "        \"\"\"Initialize Kalman Filter object for the track\"\"\"\n",
    "        if x0 is None:\n",
    "            x0 = np.array([0, 0.5, 0.2, 0, 0.5, 0.2, 0, 0.5, 0.2]) # dummy object\n",
    "        if model_type == 'ca':\n",
    "            self.filter = KalmanFilter (dim_x=9, dim_z=3)\n",
    "            self.filter.x = np.array([x0.x, 0.5, 0.2, x0.y, 0.5, 0.2, x0.z, 0.5, 0.2])\n",
    "            self.filter.F = linear_transition_matrix(dt)\n",
    "            self.filter.H = H\n",
    "            self.filter.P *= 0.1 \n",
    "            self.filter.Q = np.eye(9) * 0.005 \n",
    "            self.filter.R = np.diag(np.array([0.5, 0.2, 0.05]))* 0.001\n",
    "            \n",
    "    def update_Kalman_Filter(self, y):\n",
    "        \"\"\"Perform Kalman Filter update with observed data y\"\"\"\n",
    "        y = np.array(y)\n",
    "        self.filter.update(y)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"ID: %d, status: %s, x: %f, y:%f, z:%f, new_time: %f, pending_time: %f, objects_count: %d, frame_count: %d\"%(self.ID, self.status, self.x, self.y, self.z, self.new_time, self.pending_time, len(self.objects), len(self.frames))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"ID %d - TimeNew %d\\n - Last coords (%f,%f,%f)\" %(self.ID, self.new_time, self.x, self.y, self.z)\n",
    "    \n",
    "    \n",
    "    def detection_vs_filter(self):\n",
    "        plt.figure()\n",
    "        plt.title('Detections vs Filter for Track: '+ str(self.ID))\n",
    "        abscissa = [pos[0] for pos in self.all_positions ]\n",
    "        ordinate = [pos[1] for pos in self.all_positions ]\n",
    "        plt.ylim((np.min(ordinate)-5,np.max(ordinate)+5))\n",
    "        plt.xlim((np.min(abscissa)-5,np.max(abscissa)+5))\n",
    "        plt.scatter(abscissa[0], ordinate[0], color = 'r')\n",
    "        plt.plot(abscissa, ordinate, color = 'r', label = 'Filter')\n",
    "        plt.scatter(abscissa[-1], ordinate[-1], color = 'r')\n",
    "        abscissa = [pos.x for pos in self.objects]\n",
    "        ordinate = [pos.y for pos in self.objects]\n",
    "        plt.scatter(abscissa[0], ordinate[0], color = 'b')\n",
    "        plt.plot(abscissa, ordinate, color = 'b', label = 'Detection')\n",
    "        plt.scatter(abscissa[-1], ordinate[-1], color = 'b')\n",
    "        \n",
    "        plt.legend()\n",
    "        return\n",
    "    \n",
    "    def visualize_trajectory(self, figsize = None , s = 100):\n",
    "        \"\"\" Input camera file, frame index and size of dot in the picture (default is 100) \"\"\"\n",
    "        \n",
    "        frame_idx = self.frames[-1] #control if this can be removed\n",
    "        camera_n = int(self.objects[-1].camera)\n",
    "        matches = { \n",
    "            109: hdf5data_109,\n",
    "            130: hdf5data_130,\n",
    "            142: hdf5data_142,\n",
    "            143: hdf5data_143\n",
    "                    }\n",
    "        camera = matches[camera_n]\n",
    "        \n",
    "        frame = camera['Sequence'][str(frame_idx)]\n",
    "\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "\n",
    "            #for point in self.all_positions:\n",
    "        for point in self.all_positions:\n",
    "\n",
    "            world_pos = np.array(point)\n",
    "            fin_pos = convert_to_image_space(world_pos, camera['TMatrixWorldToCam'], camera['ProjectionMatrix'])\n",
    "            x_list.append(fin_pos[0])\n",
    "            y_list.append(fin_pos[1])\n",
    "\n",
    "        # Show image\n",
    "        a = np.asarray(frame['Image'])\n",
    "\n",
    "        if figsize is not None: \n",
    "            plt.figure(figsize = figsize)\n",
    "\n",
    "        plt.imshow(a, cmap = 'gist_gray', zorder = 1)\n",
    "        plt.scatter(x_list, y_list, s = s, color = 'hotpink', zorder = 3)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def visualize_velocities(self):\n",
    "        fig, ((ax0, ax1), (ax2, axv)) = plt.subplots(2,2)\n",
    "        \n",
    "        ax0.scatter(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[0], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax0.plot(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[0], c='black', lw=0.5)\n",
    "        ax0.set_title('vx')\n",
    "\n",
    "        ax1.scatter(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[1], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax1.plot(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[1], c='black', lw=0.5)\n",
    "        ax1.set_title('vy')\n",
    "        \n",
    "        ax2.scatter(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[2], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax2.plot(np.arange(len(self.all_velocities[0]))*dt, self.all_velocities[2], c='black', lw=0.5)\n",
    "        ax2.set_title('vz')\n",
    "        \n",
    "        vel = np.sqrt(np.array(self.all_velocities[0])**2+ np.array(self.all_velocities[1])**2+ np.array(self.all_velocities[2])**2)\n",
    "        axv.scatter(np.arange(len(self.all_velocities[0]))*dt, vel, c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        axv.plot(np.arange(len(self.all_velocities[0]))*dt, vel, c='black', lw=0.5)\n",
    "        axv.set_title('|v|')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def visualize_accelerations(self):\n",
    "        fig, ((ax0, ax1), (ax2, axv)) = plt.subplots(2,2)\n",
    "        \n",
    "        ax0.scatter(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[0], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax0.plot(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[0], c='black', lw=0.5)\n",
    "        ax0.set_title('ax')\n",
    "\n",
    "        ax1.scatter(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[1], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax1.plot(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[1], c='black', lw=0.5)\n",
    "        ax1.set_title('ay')\n",
    "        \n",
    "        ax2.scatter(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[2], c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        ax2.plot(np.arange(len(self.all_accelerations[0]))*dt, self.all_accelerations[2], c='black', lw=0.5)\n",
    "        ax2.set_title('az')\n",
    "        \n",
    "        acc = np.sqrt(np.array(self.all_accelerations[0])**2+ np.array(self.all_accelerations[1])**2+ np.array(self.all_accelerations[2])**2)\n",
    "        axv.scatter(np.arange(len(self.all_accelerations[0]))*dt, acc, c=np.array(self.pending_status), cmap='bwr', s=10)\n",
    "        axv.plot(np.arange(len(self.all_accelerations[0]))*dt, acc, c='black', lw=0.5)\n",
    "        axv.set_title('|a|')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function needed to join cameras\n",
    "\n",
    "def custom_prob(obj1, obj2):\n",
    "    \n",
    "    #Mean is center of obj1, std dimension of the boxes, we multiply cov by a coefficient related to distance in time\n",
    "    time_coef = 0.05 #0.05 Ok with 0.06 as timestep, probably better 0.03 with 0.08\n",
    "    mean = obj1[0:3]\n",
    "    std = obj1[3:6]\n",
    "    cov = np.diag(np.power(std,2)) * np.exp(np.abs(obj1[7] - obj2[7])/time_coef, dtype = np.float64)\n",
    "\n",
    "    x = obj2[:3]\n",
    "\n",
    "    m_dist_x = np.dot((x-mean).transpose(),np.linalg.inv(cov))\n",
    "    m_dist_x = np.dot(m_dist_x, (x-mean))\n",
    "    \n",
    "    dist = 1-stats.chi2.cdf(m_dist_x, 3)\n",
    "    \n",
    "    #If objs belong to same camera -> 0 prob of being same one (consider to comment this rows)\n",
    "    if dist != 1 and obj1[9] == obj2[9] and obj1[7] == obj2[7]:\n",
    "        return 0\n",
    "    \n",
    "    return dist\n",
    "\n",
    "def unify(frame):\n",
    "    \n",
    "    #Convert Frame to array\n",
    "    frame_values = frame.iloc[:,:].values\n",
    "\n",
    "    #Compute probabilities\n",
    "    dists = cdist(frame_values, frame_values, custom_prob)\n",
    "    \n",
    "    #Create index array\n",
    "    index = np.empty(shape = (len(frame.index)))\n",
    "    index[:] = np.nan\n",
    "    \n",
    "    #Compute first argmax\n",
    "    argmax = np.unravel_index(dists.argmax(), dists.shape)\n",
    "    max_value = np.max(dists) \n",
    "    \n",
    "    #Cycle on maxima\n",
    "    while max_value > 0.35:\n",
    "    \n",
    "        if argmax[0] == argmax[1]:\n",
    "            dists[argmax] = -1\n",
    "\n",
    "        if argmax[0] != argmax[1]:\n",
    "            if dists[argmax[0], argmax[1]] > 0.8 or (dists[argmax[0], argmax[1]] > 0.5 and dists[argmax[1], argmax[0]] > 0.1):\n",
    "                if np.isnan(index[argmax[1]]):\n",
    "                    if np.isnan(index[argmax[0]]):\n",
    "                        index[argmax[0]] = argmax[0]\n",
    "                    index[argmax[1]] = index[argmax[0]]\n",
    "            dists[argmax] = -1\n",
    "    \n",
    "        argmax = np.unravel_index(dists.argmax(), dists.shape)\n",
    "        max_value = dists[argmax]\n",
    "\n",
    "    #Fill index vectors\n",
    "    for i in range(index.shape[0]):\n",
    "        if np.isnan(index[i]):\n",
    "            index[i] = i\n",
    "    \n",
    "    #Add index column\n",
    "    frame['object_index'] = index\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Methods to compute IoU and associate boxes through IoU\n",
    "\n",
    "def belongs_to(point, box, isdf=False):\n",
    "    \"\"\"Utility function that returns true if the point is found within the box, false otherwise\"\"\"\n",
    "    \n",
    "    if isdf:\n",
    "        center = box[['X_box', 'Y_box', 'Z_box']].to_numpy().flatten()\n",
    "        point = np.array([i for i in point]) - center\n",
    "        anti_rotation_matrix = np.array([[np.cos(-box['angle_box'].to_numpy()[0]), -np.sin(-box['angle_box'].to_numpy()[0]), 0], \n",
    "                            [np.sin(-box['angle_box'].to_numpy()[0]), np.cos(-box['angle_box'].to_numpy()[0]), 0], \n",
    "                            [0,0,1]])\n",
    "        rot_point = anti_rotation_matrix.dot(point)\n",
    "        \n",
    "        if np.abs(rot_point[0])<box['length_box'].to_numpy()/2 and np.abs(rot_point[1])<box['width_box'].to_numpy()/2 and np.abs(rot_point[2])<box['height_box'].to_numpy()/2:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    center = np.array([i for i in box[0]])\n",
    "    point = np.array([i for i in point]) - center\n",
    "    anti_rotation_matrix = np.array([[np.cos(-box[4]), -np.sin(-box[4]), 0], \n",
    "                            [np.sin(-box[4]), np.cos(-box[4]), 0], \n",
    "                            [0,0,1]])\n",
    "    rot_point = anti_rotation_matrix.dot(point)\n",
    "    \n",
    "    if np.abs(rot_point[0])<box[1]/2 and np.abs(rot_point[1])<box[2]/2 and np.abs(rot_point[2])<box[3]/2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def compute_approx_IoU(box1, box2, attempts=100): \n",
    "    \"\"\"Compute an approximated IoU between two boxes with a Monte Carlo approach\"\"\"\n",
    "\n",
    "    # store measures in meaningful variables\n",
    "    pos1 = box1[['X_box', 'Y_box', 'Z_box']].to_numpy().flatten()\n",
    "    pos2 = box2[['X_box', 'Y_box', 'Z_box']].to_numpy().flatten()\n",
    "    length1 = box1['length_box'].to_numpy()[0]\n",
    "    width1 = box1['width_box'].to_numpy()[0]\n",
    "    height1 = box1['height_box'].to_numpy()[0]\n",
    "    length2 = box2['length_box'].to_numpy()[0]\n",
    "    width2 = box2['width_box'].to_numpy()[0]\n",
    "    height2 = box2['height_box'].to_numpy()[0]\n",
    "    diag1 = np.sqrt(length1**2+width1**2+height1**2)\n",
    "    diag2 = np.sqrt(length2**2+width2**2+height2**2)\n",
    "    rotation_matrix1 = np.array([[np.cos(box1['angle_box'].to_numpy())[0], -np.sin(box1['angle_box'].to_numpy()[0]), 0], \n",
    "                            [np.sin(box1['angle_box'].to_numpy()[0]), np.cos(box1['angle_box'].to_numpy()[0]), 0], \n",
    "                            [0,0,1]])\n",
    "    rotation_matrix2 = np.array([[np.cos(box2['angle_box'].to_numpy()[0]), -np.sin(box2['angle_box'].to_numpy()[0]), 0], \n",
    "                            [np.sin(box2['angle_box'].to_numpy()[0]), np.cos(box2['angle_box'].to_numpy()[0]), 0], \n",
    "                            [0,0,1]])\n",
    "    \n",
    "    # return 0 if boxes are non-overlapping\n",
    "    if np.sqrt((pos1[0]-pos2[0])**2+(pos1[1]-pos2[1])**2+(pos1[2]-pos2[2])**2)>max(diag1, diag2):\n",
    "        return 0\n",
    "    \n",
    "    # if an overlap exists, estimate IoU by drawing random points in each box and checking how many also belong to the other\n",
    "    intersection = 0\n",
    "    \n",
    "    for i in range(attempts):\n",
    "        u = np.random.uniform(-1,1,size=3) * np.array([length1,width1,height1])/2 \n",
    "        u = rotation_matrix1.dot(u)\n",
    "        if belongs_to(u + np.array([i for i in pos1]), box2, True):\n",
    "            intersection +=1\n",
    "        u = np.random.uniform(-1,1,size=3) * np.array([length2,width2,height2])/2 \n",
    "        u = rotation_matrix2.dot(u)\n",
    "        if belongs_to(u + np.array([i for i in pos2]), box1, True):\n",
    "            intersection +=1\n",
    "    return intersection/2/attempts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions used to associate tracks and detections\n",
    "\n",
    "def find_subsequent_boxes(track_list1, track_list2):\n",
    "    \"\"\"\n",
    "    Returns a numpy array of the best matches of boxes in track_list2 for boxes in track_list1, if any.\n",
    "    If no IoU above a fixed threshold is found, -1 is assigned.\n",
    "    \"\"\"\n",
    "    \n",
    "    iou_vals = np.zeros(shape=(len(track_list1), len(track_list2)))\n",
    "    \n",
    "    for i in range(len(track_list1)):\n",
    "        for j in range(len(track_list2)):\n",
    "\n",
    "            df1 = track_list1[i].to_df()\n",
    "            last_frame = df1.frame.max()\n",
    "            iou = compute_approx_IoU(df1[df1.frame==last_frame],track_list2[j].to_df())\n",
    "            iou_vals[i][j] = iou\n",
    "        \n",
    "    return iou_vals\n",
    "\n",
    "def track_detection_association(track_coord, obj_coord):\n",
    "    ''' Function for computing the euclidean distance between detections and predicted track positions'''\n",
    "    \n",
    "    dists = cdist(track_coord, obj_coord, 'euclidean') \n",
    "\n",
    "    return dists\n",
    "\n",
    "### Perform association of objects in previous and next frame\n",
    "\n",
    "def associate(tracks, obj_list, frame_index):\n",
    "    \n",
    "    all_tracks = tracks.items()\n",
    "    all_tracks = np.array([track for cat, trs in all_tracks if cat in ['Active', 'New', 'Pending'] for track in trs])\n",
    "    track_coord = np.array([[t.x, t.y, t.z] for t in all_tracks]) \n",
    "    track_indices = np.array([t.ID for t in all_tracks])\n",
    "    \n",
    "    if track_coord.size and len(obj_list) > 0:\n",
    "        \n",
    "        # explore with iou\n",
    "        \n",
    "        iou_values = find_subsequent_boxes(all_tracks, obj_list)\n",
    "\n",
    "        obj_coord = [(obj.x, obj.y, obj.z) for obj in obj_list]\n",
    "        dist_values = track_detection_association(track_coord, obj_coord)\n",
    "        \n",
    "        complete_dists = 0.1 * (1-iou_values) + 0.9 * dist_values\n",
    "        \n",
    "        associations = visiting_algorithm(complete_dists,len(all_tracks))\n",
    "\n",
    "        for index, ass in enumerate(associations):\n",
    "            if ass == -1:\n",
    "                all_tracks[index].update(None, frame_index)\n",
    "            else:\n",
    "                all_tracks[index].update(obj_list[ass], frame_index)\n",
    "        \n",
    "        assigned = np.where(associations != -1)\n",
    "        associations = associations[assigned]\n",
    "\n",
    "        obj_list = np.delete(obj_list, associations, axis = 0)\n",
    "\n",
    "    return obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visiting_algorithm(complete_dists, n_tracks):\n",
    "    best_dist = complete_dists.min()\n",
    "    associations = - np.ones(shape = n_tracks, dtype = np.int8)\n",
    "    object_associations = complete_dists.argmin(axis = 0)\n",
    "    best_dists_obj = complete_dists.min(axis = 0)\n",
    "    threshold = best_dist + max_dist_threshold\n",
    "    \n",
    "    object_associations[best_dists_obj > threshold] = -1\n",
    "    \n",
    "    dict_ass = {}\n",
    "    for index in range(len(associations)):\n",
    "        correspondences = np.where(object_associations==index)[0]\n",
    "        dict_ass[index] = correspondences\n",
    "        \n",
    "    \n",
    "    \n",
    "    keep_going = True\n",
    "    while keep_going:\n",
    "        \n",
    "        keep_going = False\n",
    "        for index in range(n_tracks):\n",
    "            correspondences = dict_ass[index]\n",
    "            if (np.size(correspondences) > 1):\n",
    "                keep_going = True\n",
    "                \n",
    "                best_sub_dists = best_dists_obj[correspondences]\n",
    "                # print(best_sub_dists)\n",
    "                idx = np.argmin(best_sub_dists)\n",
    "            \n",
    "                dict_ass[index] = correspondences[idx]\n",
    "                \n",
    "                # associations[index] = correspondences[idx]\n",
    "                for elem in correspondences: \n",
    "                    if (elem != correspondences[idx]):\n",
    "                        new_ass = find_seq_min(complete_dists, elem, index)\n",
    "                        new_ass_dist = complete_dists[new_ass][elem]\n",
    "                        best_dists_obj[elem] = new_ass_dist \n",
    "                        if (new_ass_dist < threshold):\n",
    "                            dict_ass[new_ass] = np.append(dict_ass[new_ass],elem)\n",
    "            \n",
    "            elif (np.size(correspondences) == 1) :\n",
    "                associations[index] = correspondences\n",
    "    \n",
    "    return associations \n",
    "\n",
    "\n",
    "def find_seq_min(complete_dists, elem, index):\n",
    "    \n",
    "    dist_copy = copy(complete_dists)\n",
    "    to_change = dist_copy[:,elem] <= dist_copy[index,elem]\n",
    "    dist_copy[to_change,elem] = np.inf \n",
    "    pos = np.argmin(dist_copy[:,elem])\n",
    "    return pos \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class tracker\n",
    "\n",
    "class Tracker:\n",
    "    \n",
    "    def __init__(self, dfs):\n",
    "        self.tracks = {'Active': [], 'Pending': [], 'Inactive': [], 'New': [], 'Removed': []}\n",
    "        self.dataframe = concatenate_dfs(dfs, ['frame', 'camera'])\n",
    "        self.track_id = 0 \n",
    "        self.time = -0.06\n",
    "        self.current_objects = pd.DataFrame()\n",
    "        self.frame_index = -1\n",
    "        \n",
    "    \n",
    "    def update_tracks(self):\n",
    "        ''' Update the status of the tracks, moving them to the different lists'''\n",
    "        for tr in self.tracks['New'][::-1]:\n",
    "            if tr.status != 'New':\n",
    "                self.tracks['New'].remove(tr)\n",
    "                self.tracks[tr.status].append(tr)\n",
    "        \n",
    "        for tr in self.tracks['Pending'][::-1]:\n",
    "            if tr.status != 'Pending':\n",
    "                self.tracks['Pending'].remove(tr)\n",
    "                self.tracks[tr.status].append(tr)\n",
    "        \n",
    "        for tr in self.tracks['Active'][::-1]:\n",
    "            if tr.status != 'Active':\n",
    "                self.tracks['Active'].remove(tr)\n",
    "                self.tracks[tr.status].append(tr)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def next_step(self):\n",
    "        '''Proceed with next time step analysis of frames'''\n",
    "        self.frame_index += 1\n",
    "        self.time += dt\n",
    "        self.current_objects = self.dataframe[np.abs(self.dataframe['elapsed_time']-self.time)<=dt/2]# very unlikely one happens to be EXACTLY in the middle\n",
    "        self.merge_collisions()\n",
    "        self.analyze_frame()\n",
    "        \n",
    "    \n",
    "    def analyze_frame(self):\n",
    "        ''' Analyze frame creating or updating trajectories'''\n",
    "        \n",
    "        frame = self.current_objects \n",
    "        obj_list = []\n",
    "        \n",
    "        # Extract all the detections in the frame\n",
    "        for index, row in frame.iterrows():\n",
    "            obj = Object(row['X_box'], row['Y_box'], row['Z_box'], row['length_box'], \n",
    "                         row['width_box'], row['height_box'], row['angle_box'], row['camera'])\n",
    "            obj_list.append(obj)\n",
    "\n",
    "        obj_list = np.array(obj_list)\n",
    "        \n",
    "        # Perform associations\n",
    "        obj_list = associate( self.tracks, obj_list, self.frame_index)\n",
    "        \n",
    "        # Check status of all tracks\n",
    "        self.update_tracks()        \n",
    "        \n",
    "        #Create new tracks for not linked objects\n",
    "        for obj in obj_list:\n",
    "            tr = Track(self.track_id, obj, self.frame_index)\n",
    "            self.track_id += 1\n",
    "            self.tracks['New'].append(tr)\n",
    "            # self.track_list[self.track_id] = []\n",
    "            # self.track_list.append('New')\n",
    "        \n",
    "        \n",
    "    def merge_collisions(self):\n",
    "        \n",
    "        if 'credibility_level' not in self.current_objects:\n",
    "            credibility_level(self.current_objects)\n",
    "        \n",
    "        \n",
    "        self.current_objects = self.current_objects[self.current_objects['credibility_level'] != 0.25]\n",
    "        \n",
    "        unify(self.current_objects)\n",
    "        labeled_df = self.current_objects\n",
    "        \n",
    "        if np.all(labeled_df.groupby(['object_index']).count()==1):\n",
    "            return \n",
    "        \n",
    "        labeled_df.loc[:,~labeled_df.columns.isin(['credibility_level', 'camera', 'object_index'])] = labeled_df.loc[:,~labeled_df.columns.isin(['credibility_level', 'camera', 'object_index'])].multiply(labeled_df.credibility_level, axis='index')\n",
    "        cameras = labeled_df.sort_values(by=['object_index', 'credibility_level'], ascending=[True,False]).groupby(['object_index']).head(1)[['object_index','camera']].set_index('object_index')\n",
    "        labeled_df = labeled_df.groupby(['object_index']).sum()\n",
    "        labeled_df = labeled_df.divide(labeled_df.credibility_level, axis='index')\n",
    "        labeled_df = labeled_df.drop(['credibility_level'], axis=1)\n",
    "        \n",
    "        labeled_df['frame'] = self.frame_index\n",
    "        try:\n",
    "            labeled_df['camera'] = cameras\n",
    "        except: \n",
    "            print(len(cameras.values), len(labeled_df['camera']))\n",
    "        \n",
    "        self.current_objects = labeled_df\n",
    "        self.current_objects['elapsed_time'] = self.time\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def return_track(self,id_):\n",
    "        for t_l in self.tracks.values():\n",
    "            for t in t_l: \n",
    "                if t.ID == id_ : \n",
    "                    return t\n",
    "        print('Track with ID ', id_, ' not found')\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def iterate_for(self,n_iter):\n",
    "        for i in range(n_iter):\n",
    "            self.next_step()\n",
    "            self.summary_track_types(i)\n",
    "        \n",
    "        cmap = plt.get_cmap('tab20')\n",
    "        num = len(cmap.colors)\n",
    "        colors = [cmap(i) for i in np.linspace(0,1,num)]\n",
    "        self.print_tracks(colors, num)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def print_tracks(self,colors,num_cols):\n",
    "        plt.figure()\n",
    "        plt.title(\"plot of Active and New tracks\")\n",
    "        for t in self.tracks['Active']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [-pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], color = colors[t.ID%num_cols])\n",
    "            \n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], color = colors[t.ID%num_cols])\n",
    "            \n",
    "        for t in self.tracks['New']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [-pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], color = colors[t.ID%num_cols])\n",
    "            \n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], color = colors[t.ID%num_cols])\n",
    "        plt.figure()\n",
    "        plt.title(\"plot of Pending and Inactive tracks\")\n",
    "        for t in self.tracks['Inactive']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [-pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], marker = \"*\", color = colors[t.ID%num_cols])\n",
    "            \n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], marker = \"*\", color = colors[t.ID%num_cols])\n",
    "            \n",
    "        for t in self.tracks['Pending']:\n",
    "            abscissa = [pos[0] for pos in t.all_positions ]\n",
    "            ordinate = [-pos[1] for pos in t.all_positions ]\n",
    "            plt.scatter(abscissa[0], ordinate[0], color = colors[t.ID%num_cols])\n",
    "            \n",
    "            plt.plot(abscissa, ordinate, color = colors[t.ID%num_cols])\n",
    "            plt.scatter(abscissa[-1], ordinate[-1], color = colors[t.ID%num_cols])\n",
    "        \n",
    "        return\n",
    "        \n",
    "    \n",
    "    def summary_track_types(self, n ):\n",
    "        print(\"-------------------------------- Iteration N \", n+1, \"--------------------------------\")\n",
    "        print(\"Active tracks: \", len(self.tracks['Active']), 4*\" \", \"New tracks: \", len(self.tracks['New']),\n",
    "              4*\" \", \"Pending tracks: \", len(self.tracks['Pending']), 4*\" \", \"Removed tracks: \", \n",
    "              len(self.tracks['Removed']) ,4*\" \", \"Inactive tracks: \", len(self.tracks['Inactive']) )\n",
    "        print(\"\\n\")\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def plot_individual_track(self, ID):\n",
    "        for cat, trs in self.tracks.items():\n",
    "            for track in trs:\n",
    "                if track.ID == ID:\n",
    "                    \n",
    "                    track.visualize_trajectory(figsize=(12,12), s=10)\n",
    "                    return\n",
    "        print(\"Object not found\")\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo and performance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tracker, analyze some frames\n",
    "TrackTrack = Tracker([df_109,df_130,df_142,df_143])\n",
    "TrackTrack.iterate_for(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tracks do we have?\n",
    "TrackTrack.track_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot all the tracks\n",
    "\n",
    "for ID in range(TrackTrack.track_id):\n",
    "    t = TrackTrack.return_track(ID)\n",
    "    print(\"Track \" + str(t.ID) + \", Status: \" + t.status )\n",
    "    TrackTrack.plot_individual_track(ID)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['Active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['New']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['Pending']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['Inactive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrackTrack.tracks['Removed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract track with specific ID\n",
    "t = TrackTrack.return_track(7)\n",
    "t.frames\n",
    "t.objects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
